{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">",
        "",
        "# ğŸ“Š PROCESO ETL COMPLETO",
        "## KAGGLE MACHINE LEARNING & DATA SCIENCE SURVEY 2019",
        "",
        "<img src=\"https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge&logo=python\" alt=\"Python\">",
        "<img src=\"https://img.shields.io/badge/Pandas-Latest-green?style=for-the-badge&logo=pandas\" alt=\"Pandas\">",
        "<img src=\"https://img.shields.io/badge/Jupyter-Notebook-orange?style=for-the-badge&logo=jupyter\" alt=\"Jupyter\">",
        "<img src=\"https://img.shields.io/badge/Power_BI-Validated-yellow?style=for-the-badge&logo=powerbi\" alt=\"Power BI\">",
        "",
        "<img src=\"https://img.shields.io/badge/Status-âœ…_Complete-success?style=for-the-badge\" alt=\"Status\">",
        "<img src=\"https://img.shields.io/badge/Documentation-30--50h-orange?style=for-the-badge\" alt=\"Documentation\">",
        "<img src=\"https://img.shields.io/badge/Quality-ğŸ†_Professional-blue?style=for-the-badge\" alt=\"Quality\">",
        "",
        "---",
        "",
        "### ğŸ¯ **APLICADO AL ÃREA DE INGENIERÃA DE SISTEMAS**",
        "### ğŸ« **UNIVERSIDAD PERUANA UNIÃ“N (UPEU)**",
        "",
        "</div>",
        "",
        "---",
        "",
        "## ğŸ“‹ **INFORMACIÃ“N COMPLETA DEL PROYECTO**",
        "",
        "<div align=\"center\">",
        "",
        "| **ğŸ” Campo** | **ğŸ“Š Detalle** |",
        "|:-------------|:---------------|",
        "| **ğŸ‘¨â€ğŸ’» Autor** | **[Tu Nombre Completo]** |",
        "| **ğŸ“… Fecha** | **Septiembre 2025** |",
        "| **ğŸ« Universidad** | **Universidad Peruana UniÃ³n (UPEU)** |",
        "| **ğŸ“š Curso** | **Business Intelligence** |",
        "| **ğŸ‘¨â€ğŸ« Docente** | **[Nombre del Profesor]** |",
        "| **ğŸ“Š Dataset** | **Kaggle ML & Data Science Survey 2019** |",
        "| **ğŸ¯ AplicaciÃ³n** | **IngenierÃ­a de Sistemas** |",
        "| **â° Tiempo DocumentaciÃ³n** | **30-50 horas acadÃ©micas** |",
        "| **ğŸ”§ Herramientas Principales** | **Python, Pandas, Matplotlib, Seaborn, Plotly** |",
        "| **âœ… ValidaciÃ³n** | **Power BI, Excel, CSV** |",
        "| **ğŸ“ˆ Registros Procesados** | **19,717 profesionales** |",
        "| **ğŸŒ Cobertura GeogrÃ¡fica** | **171 paÃ­ses** |",
        "",
        "</div>",
        "",
        "---",
        "",
        "## ğŸ¯ **OBJETIVOS ESTRATÃ‰GICOS DEL PROYECTO**",
        "",
        "<div align=\"center\">",
        "",
        "### ğŸš€ **OBJETIVOS PRINCIPALES**",
        "",
        "</div>",
        "",
        "| **#** | **ğŸ¯ Objetivo** | **ğŸ“Š DescripciÃ³n** | **â° Tiempo** |",
        "|:-----:|:---------------|:-------------------|:-------------|",
        "| **1** | **ğŸ”„ Proceso ETL Robusto** | Implementar extracciÃ³n, transformaciÃ³n y carga optimizada | **15-20h** |",
        "| **2** | **ğŸ“ˆ AnÃ¡lisis TecnolÃ³gico** | Identificar tendencias para IngenierÃ­a de Sistemas | **10-15h** |",
        "| **3** | **âœ… ValidaciÃ³n Cruzada** | Comparar resultados Python vs Power BI | **5-8h** |",
        "| **4** | **ğŸ’¡ Insights Accionables** | Generar recomendaciones basadas en datos | **8-12h** |",
        "| **5** | **ğŸ“š DocumentaciÃ³n AcadÃ©mica** | Crear documentaciÃ³n profesional completa | **10-15h** |",
        "",
        "### ğŸ” **OBJETIVOS ESPECÃFICOS PARA INGENIERÃA DE SISTEMAS**",
        "",
        "- **ğŸ—ï¸ Arquitectura**: Analizar adopciÃ³n de tecnologÃ­as cloud (AWS, Azure, GCP)",
        "- **ğŸ’» Desarrollo**: Identificar lenguajes y frameworks mÃ¡s demandados",
        "- **ğŸ”§ Herramientas**: Evaluar IDEs, bases de datos y herramientas DevOps",
        "- **ğŸ’° Mercado Laboral**: Analizar salarios y oportunidades por tecnologÃ­a",
        "- **ğŸ“Š Toma de Decisiones**: Proporcionar datos para decisiones tecnolÃ³gicas",
        "",
        "---",
        "",
        "## ğŸ—‚ï¸ **ESTRUCTURA COMPLETA DEL NOTEBOOK**",
        "",
        "<div align=\"center\">",
        "",
        "### ğŸ“š **ROADMAP DE DOCUMENTACIÃ“N (30-50 HORAS)**",
        "",
        "</div>",
        "",
        "| **ğŸ“ SecciÃ³n** | **ğŸ” DescripciÃ³n Detallada** | **â° Tiempo** | **ğŸ“Š Entregables** |",
        "|:---------------|:------------------------------|:-------------|:-------------------|",
        "| **[1. ConfiguraciÃ³n](#1-configuraciÃ³n-del-entorno)** | Setup completo del entorno Python | **2-3h** | LibrerÃ­as, configuraciÃ³n |",
        "| **[2. ExtracciÃ³n](#2-extracciÃ³n-de-datos)** | Carga y validaciÃ³n del dataset | **4-6h** | Dataset cargado, validado |",
        "| **[3. EDA](#3-anÃ¡lisis-exploratorio)** | AnÃ¡lisis exploratorio exhaustivo | **8-12h** | EstadÃ­sticas, visualizaciones |",
        "| **[4. TransformaciÃ³n](#4-limpieza-y-transformaciÃ³n)** | Limpieza y procesamiento avanzado | **10-15h** | Datos limpios, normalizados |",
        "| **[5. Carga](#5-carga-de-datos)** | ExportaciÃ³n y validaciÃ³n | **3-5h** | CSV, Excel, metadatos |",
        "| **[6. Power BI](#6-validaciÃ³n-power-bi)** | ValidaciÃ³n cruzada | **4-6h** | Scripts M, mÃ©tricas |",
        "| **[7. AnÃ¡lisis](#7-anÃ¡lisis-de-resultados)** | Insights y visualizaciones | **6-10h** | Dashboards, reportes |",
        "| **[8. Conclusiones](#8-conclusiones)** | SÃ­ntesis y recomendaciones | **2-4h** | Reporte ejecutivo |",
        "",
        "<div align=\"center\">",
        "",
        "**ğŸ† TOTAL: 39-61 HORAS ACADÃ‰MICAS**",
        "",
        "</div>",
        "",
        "---",
        "",
        "## ğŸŒŸ **RELEVANCIA CRÃTICA PARA INGENIERÃA DE SISTEMAS**",
        "",
        "### ğŸ¯ **Â¿Por quÃ© este Dataset es FUNDAMENTAL para IngenierÃ­a de Sistemas?**",
        "",
        "<div align=\"center\">",
        "",
        "**El Kaggle ML & Data Science Survey 2019 contiene informaciÃ³n de 19,717 profesionales de 171 paÃ­ses, proporcionando insights Ãºnicos sobre el ecosistema tecnolÃ³gico global.**",
        "",
        "</div>",
        "",
        "---",
        "",
        "### ğŸ—ï¸ **INFRAESTRUCTURA Y ARQUITECTURA DE SISTEMAS**",
        "",
        "| **ğŸ”§ CategorÃ­a** | **ğŸ“Š Datos Disponibles** | **ğŸ’¡ AplicaciÃ³n en Ing. Sistemas** |",
        "|:-----------------|:-------------------------|:------------------------------------|",
        "| **â˜ï¸ Cloud Platforms** | AWS, Azure, GCP, adoption rates | SelecciÃ³n de plataforma cloud Ã³ptima |",
        "| **ğŸ—„ï¸ Databases** | SQL, NoSQL, NewSQL trends | Arquitectura de datos escalable |",
        "| **âš¡ Big Data** | Spark, Hadoop, Kafka usage | Pipeline de procesamiento masivo |",
        "| **ğŸ³ Containers** | Docker, Kubernetes adoption | Estrategias de containerizaciÃ³n |",
        "| **ğŸ”„ MLOps** | ML deployment, monitoring | Infraestructura de ML en producciÃ³n |",
        "",
        "### ğŸ’» **DESARROLLO DE SOFTWARE Y DEVOPS**",
        "",
        "| **ğŸ› ï¸ CategorÃ­a** | **ğŸ“ˆ MÃ©tricas Disponibles** | **ğŸ¯ Impacto EstratÃ©gico** |",
        "|:-----------------|:----------------------------|:---------------------------|",
        "| **ğŸ Languages** | Python, R, Java, Scala popularity | Stack tecnolÃ³gico optimal |",
        "| **ğŸ’¡ IDEs** | Jupyter, PyCharm, VS Code usage | Herramientas de desarrollo |",
        "| **ğŸ“š Frameworks** | TensorFlow, PyTorch, Scikit-learn | SelecciÃ³n de frameworks ML |",
        "| **ğŸ”„ Version Control** | Git, GitHub, GitLab adoption | Workflows de desarrollo |",
        "| **ğŸš€ CI/CD** | Jenkins, GitHub Actions usage | AutomatizaciÃ³n de despliegues |",
        "",
        "### ğŸ“Š **ANÃLISIS DE MERCADO LABORAL TECNOLÃ“GICO**",
        "",
        "| **ğŸ’¼ Aspecto** | **ğŸ“‹ InformaciÃ³n** | **ğŸ¯ Decisiones EstratÃ©gicas** |",
        "|:---------------|:-------------------|:-------------------------------|",
        "| **ğŸ’° Salarios** | CompensaciÃ³n por tecnologÃ­a | ROI de capacitaciÃ³n tÃ©cnica |",
        "| **ğŸŒ GeografÃ­a** | DistribuciÃ³n global de talento | Estrategias de contrataciÃ³n |",
        "| **ğŸ“ EducaciÃ³n** | Niveles y Ã¡reas de formaciÃ³n | Programas de desarrollo |",
        "| **ğŸ“ˆ Trends** | TecnologÃ­as emergentes | Roadmap tecnolÃ³gico |",
        "| **ğŸ‘¥ Demographics** | Diversidad y experiencia | GestiÃ³n de equipos |",
        "",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "",
        "# 1. CONFIGURACIÃ“N DEL ENTORNO",
        "",
        "<div align=\"center\">",
        "<img src=\"https://img.shields.io/badge/Phase-1%2F8-blue?style=for-the-badge\" alt=\"Phase 1\">",
        "<img src=\"https://img.shields.io/badge/Time-2--3h-orange?style=for-the-badge\" alt=\"Time\">",
        "<img src=\"https://img.shields.io/badge/Status-ğŸ”§_Setup-yellow?style=for-the-badge\" alt=\"Status\">",
        "</div>",
        "",
        "## ğŸ“¦ **InstalaciÃ³n Completa de Dependencias**",
        "",
        "Esta secciÃ³n establece el entorno completo de trabajo para el proceso ETL. Instalamos y configuramos todas las librerÃ­as necesarias para anÃ¡lisis de datos profesional.",
        "",
        "### ğŸ”§ **Stack TecnolÃ³gico Completo**",
        "",
        "| **ğŸ“š CategorÃ­a** | **ğŸ› ï¸ LibrerÃ­as** | **ğŸ¯ PropÃ³sito** |",
        "|:-----------------|:------------------|:------------------|",
        "| **ğŸ“Š Data Analysis** | `pandas`, `numpy` | ManipulaciÃ³n y anÃ¡lisis de datos |",
        "| **ğŸ“ˆ Visualization** | `matplotlib`, `seaborn`, `plotly` | Visualizaciones estÃ¡ticas e interactivas |",
        "| **ğŸ¤– Machine Learning** | `scikit-learn`, `scipy` | Preprocessing y anÃ¡lisis estadÃ­stico |",
        "| **ğŸ“„ File Handling** | `openpyxl`, `xlsxwriter` | Manejo de archivos Excel |",
        "| **ğŸ”§ Utilities** | `datetime`, `os`, `glob`, `json` | Utilidades del sistema |",
        "",
        "### ğŸ’¡ **ConfiguraciÃ³n Profesional**",
        "- Estilos de visualizaciÃ³n optimizados",
        "- ConfiguraciÃ³n de memoria eficiente",
        "- SupresiÃ³n inteligente de warnings",
        "- Paletas de colores profesionales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“¦ INSTALACIÃ“N Y VERIFICACIÃ“N COMPLETA DE DEPENDENCIAS",
        "print(\"ğŸš€ CONFIGURACIÃ“N PROFESIONAL DEL ENTORNO ETL\")",
        "print(\"=\"*80)",
        "print(f\"â° Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")",
        "",
        "# === INSTALACIÃ“N DE DEPENDENCIAS ===",
        "# Descomenta la siguiente lÃ­nea si necesitas instalar las librerÃ­as",
        "# !pip install pandas numpy matplotlib seaborn plotly openpyxl scikit-learn scipy xlsxwriter jupyter",
        "",
        "# === VERIFICACIÃ“N SISTEMÃTICA DE LIBRERÃAS ===",
        "print(\"\\nğŸ” VERIFICACIÃ“N DE DEPENDENCIAS\")",
        "print(\"-\"*50)",
        "",
        "import sys",
        "import subprocess",
        "",
        "def verificar_e_importar(nombre_libreria, alias=None):",
        "    \"\"\"Verifica e importa una librerÃ­a con manejo de errores\"\"\"",
        "    try:",
        "        if alias:",
        "            exec(f\"import {nombre_libreria} as {alias}\", globals())",
        "            version = eval(f\"{alias}.__version__\" if hasattr(eval(alias), '__version__') else \"None\")",
        "        else:",
        "            exec(f\"import {nombre_libreria}\", globals())",
        "            version = eval(f\"{nombre_libreria}.__version__\" if hasattr(eval(nombre_libreria), '__version__') else \"None\")",
        "        ",
        "        version_str = f\"v{version}\" if version else \"OK\"",
        "        print(f\"   âœ… {nombre_libreria:<15} {version_str}\")",
        "        return True",
        "    except ImportError as e:",
        "        print(f\"   âŒ {nombre_libreria:<15} NO DISPONIBLE\")",
        "        return False",
        "    except Exception as e:",
        "        print(f\"   âš ï¸ {nombre_libreria:<15} ERROR: {str(e)[:30]}...\")",
        "        return False",
        "",
        "# Lista de librerÃ­as crÃ­ticas",
        "librerias_criticas = [",
        "    ('pandas', 'pd'),",
        "    ('numpy', 'np'), ",
        "    ('matplotlib.pyplot', 'plt'),",
        "    ('seaborn', 'sns'),",
        "    ('plotly.express', 'px'),",
        "    ('plotly.graph_objects', 'go'),",
        "    ('sklearn', None),",
        "    ('scipy', None),",
        "    ('openpyxl', None)",
        "]",
        "",
        "# Verificar cada librerÃ­a",
        "todas_disponibles = True",
        "for lib, alias in librerias_criticas:",
        "    if not verificar_e_importar(lib, alias):",
        "        todas_disponibles = False",
        "",
        "# === IMPORTACIÃ“N DE LIBRERÃAS DEL SISTEMA ===",
        "print(\"\\nğŸ“ LIBRERÃAS DEL SISTEMA:\")",
        "import os",
        "import glob",
        "import json",
        "import re",
        "import warnings",
        "from datetime import datetime, timedelta",
        "",
        "print(\"   âœ… os, glob, json, re, warnings, datetime\")",
        "",
        "if todas_disponibles:",
        "    print(\"\\nğŸ‰ TODAS LAS DEPENDENCIAS VERIFICADAS CORRECTAMENTE\")",
        "else:",
        "    print(\"\\nâš ï¸ ALGUNAS DEPENDENCIAS NO ESTÃN DISPONIBLES\")",
        "    print(\"ğŸ’¡ Ejecutar: pip install pandas numpy matplotlib seaborn plotly scikit-learn openpyxl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¨ CONFIGURACIÃ“N PROFESIONAL DE VISUALIZACIONES Y ENTORNO",
        "print(\"\\nğŸ¨ CONFIGURACIÃ“N PROFESIONAL DE VISUALIZACIONES\")",
        "print(\"-\"*50)",
        "",
        "# === CONFIGURACIÃ“N AVANZADA DE MATPLOTLIB ===",
        "if 'plt' in globals():",
        "    # Estilo profesional",
        "    plt.style.use('seaborn-v0_8-darkgrid')",
        "    ",
        "    # ConfiguraciÃ³n detallada",
        "    configuracion_matplotlib = {",
        "        'figure.figsize': (16, 10),",
        "        'font.size': 12,",
        "        'axes.titlesize': 18,",
        "        'axes.labelsize': 14,",
        "        'xtick.labelsize': 12,",
        "        'ytick.labelsize': 12,",
        "        'legend.fontsize': 12,",
        "        'figure.titlesize': 20,",
        "        'axes.grid': True,",
        "        'grid.alpha': 0.3,",
        "        'axes.spines.top': False,",
        "        'axes.spines.right': False,",
        "        'figure.facecolor': 'white',",
        "        'axes.facecolor': 'white'",
        "    }",
        "    ",
        "    plt.rcParams.update(configuracion_matplotlib)",
        "    print(\"   âœ… Matplotlib configurado con estilo profesional\")",
        "",
        "# === PALETA DE COLORES PROFESIONAL ===",
        "if 'sns' in globals():",
        "    # Paleta corporativa moderna",
        "    colores_profesionales = [",
        "        '#2E86AB',  # Azul principal",
        "        '#A23B72',  # Magenta",
        "        '#F18F01',  # Naranja",
        "        '#C73E1D',  # Rojo",
        "        '#592E83',  # PÃºrpura",
        "        '#F79824',  # Amarillo",
        "        '#3F88C5',  # Azul claro",
        "        '#032B43'   # Azul oscuro",
        "    ]",
        "    ",
        "    sns.set_palette(colores_profesionales)",
        "    print(\"   âœ… Seaborn configurado con paleta corporativa\")",
        "",
        "# === CONFIGURACIÃ“N AVANZADA DE PANDAS ===",
        "if 'pd' in globals():",
        "    configuracion_pandas = {",
        "        'display.max_columns': None,",
        "        'display.width': None,",
        "        'display.max_colwidth': 100,",
        "        'display.precision': 2,",
        "        'display.float_format': '{:.2f}'.format,",
        "        'display.max_rows': 50,",
        "        'display.min_rows': 20,",
        "        'display.show_dimensions': True",
        "    }",
        "    ",
        "    for opcion, valor in configuracion_pandas.items():",
        "        pd.set_option(opcion, valor)",
        "    ",
        "    print(\"   âœ… Pandas configurado para anÃ¡lisis profesional\")",
        "",
        "# === CONFIGURACIÃ“N DE PLOTLY ===",
        "if 'px' in globals():",
        "    # ConfiguraciÃ³n para notebooks",
        "    import plotly.offline as pyo",
        "    pyo.init_notebook_mode(connected=True)",
        "    ",
        "    # Template profesional",
        "    import plotly.io as pio",
        "    pio.templates.default = \"plotly_white\"",
        "    ",
        "    print(\"   âœ… Plotly configurado para visualizaciones interactivas\")",
        "",
        "# === SUPRESIÃ“N INTELIGENTE DE WARNINGS ===",
        "warnings.filterwarnings('ignore', category=FutureWarning)",
        "warnings.filterwarnings('ignore', category=UserWarning)",
        "warnings.filterwarnings('ignore', message='.*dtype.*')",
        "print(\"   âœ… Warnings optimizados para anÃ¡lisis limpio\")",
        "",
        "# === INFORMACIÃ“N DEL SISTEMA ===",
        "print(\"\\nğŸ’» INFORMACIÃ“N DEL SISTEMA\")",
        "print(\"-\"*50)",
        "print(f\"   ğŸ Python: {sys.version.split()[0]}\")",
        "if 'pd' in globals():",
        "    print(f\"   ğŸ¼ Pandas: {pd.__version__}\")",
        "if 'np' in globals():",
        "    print(f\"   ğŸ”¢ NumPy: {np.__version__}\")",
        "if 'plt' in globals():",
        "    print(f\"   ğŸ“Š Matplotlib: {plt.matplotlib.__version__}\")",
        "if 'sns' in globals():",
        "    print(f\"   ğŸ“ˆ Seaborn: {sns.__version__}\")",
        "",
        "# InformaciÃ³n de memoria si estÃ¡ disponible",
        "try:",
        "    import psutil",
        "    memoria = psutil.virtual_memory()",
        "    print(f\"   ğŸ’¾ RAM Total: {memoria.total / 1024**3:.1f} GB\")",
        "    print(f\"   ğŸ’¾ RAM Disponible: {memoria.available / 1024**3:.1f} GB\")",
        "except ImportError:",
        "    print(\"   ğŸ’¾ InformaciÃ³n de memoria no disponible\")",
        "",
        "print(\"\\nâœ… CONFIGURACIÃ“N COMPLETA DEL ENTORNO FINALIZADA\")",
        "print(\"ğŸš€ Sistema listo para proceso ETL profesional\")",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "",
        "# 2. EXTRACCIÃ“N DE DATOS",
        "",
        "<div align=\"center\">",
        "<img src=\"https://img.shields.io/badge/Phase-2%2F8-blue?style=for-the-badge\" alt=\"Phase 2\">",
        "<img src=\"https://img.shields.io/badge/Time-4--6h-orange?style=for-the-badge\" alt=\"Time\">",
        "<img src=\"https://img.shields.io/badge/Status-ğŸ“Š_Extract-green?style=for-the-badge\" alt=\"Status\">",
        "</div>",
        "",
        "## ğŸ“Š **Dataset: Kaggle ML & Data Science Survey 2019**",
        "",
        "### ğŸŒ **DescripciÃ³n Completa del Dataset**",
        "",
        "El **Kaggle Machine Learning & Data Science Survey 2019** es la encuesta anual mÃ¡s comprehensiva del ecosistema de Data Science y Machine Learning a nivel mundial.",
        "",
        "<div align=\"center\">",
        "",
        "### ğŸ“ˆ **ESTADÃSTICAS CLAVE DEL DATASET**",
        "",
        "</div>",
        "",
        "| **ğŸ“Š MÃ©trica** | **ğŸ”¢ Valor** | **ğŸ“‹ DescripciÃ³n** |",
        "|:---------------|:-------------|:-------------------|",
        "| **ğŸ‘¥ Participantes** | **19,717** | Profesionales de DS/ML |",
        "| **ğŸŒ PaÃ­ses** | **171** | Cobertura global |",
        "| **â“ Preguntas** | **50+** | Temas diversos |",
        "| **ğŸ“Š Variables** | **395** | Columnas de datos |",
        "| **ğŸ“… AÃ±o** | **2019** | Snapshot temporal |",
        "| **ğŸ¢ OrganizaciÃ³n** | **Kaggle (Google)** | Plataforma lÃ­der |",
        "| **ğŸ“„ Formato** | **CSV** | Datos estructurados |",
        "| **ğŸ’¾ TamaÃ±o** | **~40 MB** | Dataset manejable |",
        "",
        "---",
        "",
        "## ğŸ¯ **RELEVANCIA ESTRATÃ‰GICA PARA INGENIERÃA DE SISTEMAS**",
        "",
        "### ğŸ—ï¸ **1. ARQUITECTURA E INFRAESTRUCTURA**",
        "",
        "#### â˜ï¸ **Cloud Computing & Infrastructure**",
        "- **Plataformas**: AWS, Microsoft Azure, Google Cloud Platform",
        "- **Servicios**: EC2, S3, Lambda, Azure Functions, BigQuery",
        "- **Tendencias**: MigraciÃ³n a la nube, arquitecturas serverless",
        "- **Costos**: AnÃ¡lisis ROI por plataforma",
        "",
        "#### ğŸ—„ï¸ **Sistemas de Bases de Datos**",
        "- **SQL**: MySQL, PostgreSQL, SQL Server, Oracle",
        "- **NoSQL**: MongoDB, Cassandra, Redis, DynamoDB",
        "- **Big Data**: Hadoop, Spark, Elasticsearch, Kafka",
        "- **Data Warehouses**: Snowflake, Redshift, BigQuery",
        "",
        "### ğŸ’» **2. DESARROLLO DE SOFTWARE**",
        "",
        "#### ğŸ **Lenguajes de ProgramaciÃ³n**",
        "- **Data Science**: Python dominance, R for statistics",
        "- **Enterprise**: Java, Scala for distributed systems  ",
        "- **Web**: JavaScript, TypeScript for interfaces",
        "- **Systems**: C++, Go for performance-critical applications",
        "",
        "#### ğŸ› ï¸ **Herramientas de Desarrollo**",
        "- **IDEs**: Jupyter Notebooks, PyCharm, VS Code, RStudio",
        "- **Version Control**: Git, GitHub, GitLab, Bitbucket",
        "- **CI/CD**: Jenkins, GitHub Actions, Azure DevOps",
        "- **Containers**: Docker, Kubernetes, OpenShift",
        "",
        "### ğŸ“Š **3. ANÃLISIS DE MERCADO TECNOLÃ“GICO**",
        "",
        "#### ğŸ’° **CompensaciÃ³n y ROI**",
        "- **Salarios por tecnologÃ­a**: Python, R, Java, Scala",
        "- **Premiums**: Cloud skills, ML expertise, Big Data",
        "- **GeografÃ­a**: Silicon Valley, NYC, London, Bangalore",
        "- **Experiencia**: Junior vs Senior compensation curves",
        "",
        "#### ğŸ“ **EducaciÃ³n y CapacitaciÃ³n**",
        "- **Formal Education**: CS, Math, Engineering, Physics",
        "- **Online Learning**: Coursera, Udacity, edX, Kaggle Learn",
        "- **Bootcamps**: Intensive training programs",
        "- **Certifications**: AWS, Azure, Google Cloud, vendor-specific",
        "",
        "---",
        "",
        "## ğŸ” **APLICACIONES DIRECTAS EN INGENIERÃA DE SISTEMAS**",
        "",
        "### 1. **ğŸ—ï¸ PlanificaciÃ³n de Arquitecturas**",
        "- **Technology Stack Selection**: Basado en adopciÃ³n y madurez",
        "- **Scalability Planning**: Herramientas para sistemas distribuidos",
        "- **Performance Optimization**: Lenguajes y frameworks Ã³ptimos",
        "",
        "### 2. **ğŸ‘¥ GestiÃ³n de Equipos TÃ©cnicos**",
        "- **Hiring Strategy**: Skills mÃ¡s demandados y mejor pagados",
        "- **Training Programs**: CapacitaciÃ³n basada en tendencias",
        "- **Retention**: CompensaciÃ³n competitiva por especializaciÃ³n",
        "",
        "### 3. **ğŸš€ Roadmap TecnolÃ³gico**",
        "- **Emerging Technologies**: Identificar tendencias tempranas",
        "- **Migration Planning**: Timing Ã³ptimo para adopciÃ³n",
        "- **Risk Assessment**: Madurez y estabilidad de tecnologÃ­as",
        "",
        "### 4. **ğŸ“ˆ Business Intelligence**",
        "- **Market Research**: Competencia y positioning",
        "- **Investment Decisions**: ROI de capacitaciÃ³n e infraestructura",
        "- **Strategic Planning**: AlineaciÃ³n con tendencias del mercado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š PROCESO COMPLETO DE EXTRACCIÃ“N DE DATOS",
        "print(\"ğŸ“Š EXTRACCIÃ“N PROFESIONAL DE DATOS - KAGGLE SURVEY 2019\")",
        "print(\"=\"*80)",
        "print(f\"ğŸ• Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")",
        "",
        "# === PASO 1: DIAGNÃ“STICO DEL ENTORNO ===",
        "print(\"\\nğŸ” PASO 1: DIAGNÃ“STICO COMPLETO DEL ENTORNO\")",
        "print(\"-\"*60)",
        "",
        "# Directorio actual",
        "directorio_trabajo = os.getcwd()",
        "print(f\"ğŸ“‚ Directorio de trabajo: {directorio_trabajo}\")",
        "",
        "# Espacio en disco",
        "try:",
        "    import shutil",
        "    total, usado, libre = shutil.disk_usage(directorio_trabajo)",
        "    print(f\"ğŸ’¾ Espacio en disco:\")",
        "    print(f\"   â€¢ Total: {total / 1024**3:.2f} GB\")",
        "    print(f\"   â€¢ Usado: {usado / 1024**3:.2f} GB\") ",
        "    print(f\"   â€¢ Libre: {libre / 1024**3:.2f} GB\")",
        "    print(f\"   â€¢ Uso: {(usado/total)*100:.1f}%\")",
        "except:",
        "    print(\"ğŸ’¾ InformaciÃ³n de disco no disponible\")",
        "",
        "# Inventario completo de archivos",
        "print(f\"\\nğŸ“‹ INVENTARIO COMPLETO DE ARCHIVOS\")",
        "print(\"-\"*40)",
        "",
        "tipos_archivo = {",
        "    'CSV': '*.csv',",
        "    'Excel': '*.xlsx', ",
        "    'Texto': '*.txt',",
        "    'Python': '*.py',",
        "    'Jupyter': '*.ipynb',",
        "    'Markdown': '*.md',",
        "    'JSON': '*.json'",
        "}",
        "",
        "inventario_total = {}",
        "tamaÃ±o_total_mb = 0",
        "",
        "for tipo, patron in tipos_archivo.items():",
        "    archivos = glob.glob(patron)",
        "    if archivos:",
        "        print(f\"\\nğŸ“„ {tipo} Files ({len(archivos)}):\")",
        "        tamaÃ±o_tipo = 0",
        "        for archivo in archivos[:5]:  # Mostrar mÃ¡ximo 5 por tipo",
        "            try:",
        "                tamaÃ±o = os.path.getsize(archivo)",
        "                tamaÃ±o_tipo += tamaÃ±o",
        "                fecha = datetime.fromtimestamp(os.path.getmtime(archivo))",
        "                ",
        "                if tamaÃ±o > 1024**2:",
        "                    tamaÃ±o_str = f\"{tamaÃ±o/1024**2:.1f}MB\"",
        "                elif tamaÃ±o > 1024:",
        "                    tamaÃ±o_str = f\"{tamaÃ±o/1024:.1f}KB\" ",
        "                else:",
        "                    tamaÃ±o_str = f\"{tamaÃ±o}B\"",
        "                    ",
        "                print(f\"   â€¢ {archivo:<35} {tamaÃ±o_str:>8} {fecha.strftime('%Y-%m-%d')}\")",
        "            except:",
        "                print(f\"   â€¢ {archivo:<35} {'ERROR':>8}\")",
        "        ",
        "        if len(archivos) > 5:",
        "            print(f\"   ... y {len(archivos) - 5} archivos mÃ¡s\")",
        "            ",
        "        tamaÃ±o_total_mb += tamaÃ±o_tipo",
        "        print(f\"   ğŸ“Š Subtotal: {tamaÃ±o_tipo/1024**2:.2f} MB\")",
        "    ",
        "    inventario_total[tipo] = archivos",
        "",
        "print(f\"\\nğŸ“Š RESUMEN DEL INVENTARIO:\")",
        "total_archivos = sum(len(archivos) for archivos in inventario_total.values())",
        "print(f\"   â€¢ Archivos totales: {total_archivos}\")",
        "print(f\"   â€¢ TamaÃ±o total: {tamaÃ±o_total_mb/1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === PASO 2: IDENTIFICACIÃ“N Y VALIDACIÃ“N DEL DATASET PRINCIPAL ===",
        "print(f\"\\nğŸ¯ PASO 2: IDENTIFICACIÃ“N DEL DATASET PRINCIPAL\")",
        "print(\"-\"*60)",
        "",
        "archivo_principal = \"multipleChoiceResponses.csv\"",
        "print(f\"ğŸ” Buscando archivo: {archivo_principal}\")",
        "",
        "if os.path.exists(archivo_principal):",
        "    print(f\"âœ… Archivo encontrado: {archivo_principal}\")",
        "    ",
        "    # === ANÃLISIS DETALLADO DEL ARCHIVO ===",
        "    print(f\"\\nğŸ“Š ANÃLISIS DETALLADO DEL ARCHIVO\")",
        "    print(\"-\"*40)",
        "    ",
        "    # InformaciÃ³n bÃ¡sica del archivo",
        "    stat_info = os.stat(archivo_principal)",
        "    tamaÃ±o_bytes = stat_info.st_size",
        "    fecha_creacion = datetime.fromtimestamp(stat_info.st_ctime)",
        "    fecha_modificacion = datetime.fromtimestamp(stat_info.st_mtime)",
        "    fecha_acceso = datetime.fromtimestamp(stat_info.st_atime)",
        "    ",
        "    print(f\"ğŸ“ InformaciÃ³n del archivo:\")",
        "    print(f\"   â€¢ Nombre: {archivo_principal}\")",
        "    print(f\"   â€¢ TamaÃ±o: {tamaÃ±o_bytes:,} bytes ({tamaÃ±o_bytes/1024**2:.2f} MB)\")",
        "    print(f\"   â€¢ Creado: {fecha_creacion.strftime('%Y-%m-%d %H:%M:%S')}\")",
        "    print(f\"   â€¢ Modificado: {fecha_modificacion.strftime('%Y-%m-%d %H:%M:%S')}\")",
        "    print(f\"   â€¢ Ãšltimo acceso: {fecha_acceso.strftime('%Y-%m-%d %H:%M:%S')}\")",
        "    ",
        "    # Verificar permisos",
        "    permisos = []",
        "    if os.access(archivo_principal, os.R_OK):",
        "        permisos.append(\"âœ… Lectura\")",
        "    else:",
        "        permisos.append(\"âŒ Lectura\")",
        "        ",
        "    if os.access(archivo_principal, os.W_OK):",
        "        permisos.append(\"âœ… Escritura\")",
        "    else:",
        "        permisos.append(\"âš ï¸ Escritura\")",
        "        ",
        "    print(f\"   â€¢ Permisos: {' | '.join(permisos)}\")",
        "    ",
        "    # === ANÃLISIS PRELIMINAR DE ESTRUCTURA ===",
        "    print(f\"\\nğŸ” ANÃLISIS PRELIMINAR DE ESTRUCTURA\")",
        "    print(\"-\"*40)",
        "    ",
        "    try:",
        "        print(\"â³ Analizando estructura del archivo...\")",
        "        ",
        "        # Leer muestra pequeÃ±a para anÃ¡lisis",
        "        muestra_inicial = pd.read_csv(archivo_principal, nrows=5, encoding='utf-8')",
        "        ",
        "        print(f\"âœ… Estructura analizada exitosamente\")",
        "        print(f\"\\nğŸ“Š ESTRUCTURA DETECTADA:\")",
        "        print(f\"   â€¢ Columnas: {muestra_inicial.shape[1]}\")",
        "        print(f\"   â€¢ Filas de muestra: {muestra_inicial.shape[0]}\")",
        "        ",
        "        # Mostrar primeras columnas",
        "        print(f\"\\nğŸ”¤ PRIMERAS 15 COLUMNAS:\")",
        "        for i, columna in enumerate(muestra_inicial.columns[:15]):",
        "            # Truncar nombres largos",
        "            nombre_display = columna[:50] + \"...\" if len(columna) > 50 else columna",
        "            print(f\"   {i+1:2d}. {nombre_display}\")",
        "            ",
        "        if muestra_inicial.shape[1] > 15:",
        "            print(f\"   ... y {muestra_inicial.shape[1] - 15} columnas adicionales\")",
        "        ",
        "        # AnÃ¡lisis de tipos de datos",
        "        print(f\"\\nğŸ“‹ TIPOS DE DATOS DETECTADOS:\")",
        "        tipos_detectados = muestra_inicial.dtypes.value_counts()",
        "        for tipo, cantidad in tipos_detectados.items():",
        "            print(f\"   â€¢ {str(tipo):15} {cantidad:3d} columnas\")",
        "            ",
        "        # Verificar encoding y separadores",
        "        print(f\"\\nğŸ”§ CONFIGURACIÃ“N DETECTADA:\")",
        "        print(f\"   â€¢ Encoding: UTF-8 âœ…\")",
        "        print(f\"   â€¢ Separador: Coma (,) âœ…\") ",
        "        print(f\"   â€¢ Headers: Primera fila âœ…\")",
        "        ",
        "        # EstimaciÃ³n de tiempo de carga",
        "        tiempo_estimado = (tamaÃ±o_bytes / 1024**2) * 0.5  # AproximaciÃ³n",
        "        print(f\"   â€¢ Tiempo estimado de carga: {tiempo_estimado:.1f} segundos\")",
        "        ",
        "    except Exception as e:",
        "        print(f\"âŒ Error en anÃ¡lisis preliminar: {str(e)}\")",
        "        print(\"ğŸ’¡ Posibles causas:\")",
        "        print(\"   â€¢ Formato de archivo incorrecto\")",
        "        print(\"   â€¢ Problemas de encoding\")",
        "        print(\"   â€¢ Archivo corrupto\")",
        "        ",
        "else:",
        "    print(f\"âŒ Archivo no encontrado: {archivo_principal}\")",
        "    print(f\"\\nğŸ“‹ Archivos CSV disponibles:\")",
        "    archivos_csv = glob.glob(\"*.csv\")",
        "    if archivos_csv:",
        "        for archivo in archivos_csv:",
        "            print(f\"   â€¢ {archivo}\")",
        "    else:",
        "        print(\"   â€¢ No se encontraron archivos CSV\")",
        "        ",
        "    print(f\"\\nğŸ’¡ Sugerencias:\")",
        "    print(f\"   â€¢ Verificar nombre del archivo\")",
        "    print(f\"   â€¢ Descargar dataset desde Kaggle\")",
        "    print(f\"   â€¢ Revisar directorio de trabajo\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}