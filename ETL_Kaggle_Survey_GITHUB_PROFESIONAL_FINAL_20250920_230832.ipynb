{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">",
        "",
        "# 📊 PROCESO ETL COMPLETO",
        "## KAGGLE MACHINE LEARNING & DATA SCIENCE SURVEY 2019",
        "",
        "<img src=\"https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge&logo=python\" alt=\"Python\">",
        "<img src=\"https://img.shields.io/badge/Pandas-Latest-green?style=for-the-badge&logo=pandas\" alt=\"Pandas\">",
        "<img src=\"https://img.shields.io/badge/Jupyter-Notebook-orange?style=for-the-badge&logo=jupyter\" alt=\"Jupyter\">",
        "<img src=\"https://img.shields.io/badge/Power_BI-Validated-yellow?style=for-the-badge&logo=powerbi\" alt=\"Power BI\">",
        "",
        "<img src=\"https://img.shields.io/badge/Status-✅_Complete-success?style=for-the-badge\" alt=\"Status\">",
        "<img src=\"https://img.shields.io/badge/Documentation-30--50h-orange?style=for-the-badge\" alt=\"Documentation\">",
        "<img src=\"https://img.shields.io/badge/Quality-🏆_Professional-blue?style=for-the-badge\" alt=\"Quality\">",
        "",
        "---",
        "",
        "### 🎯 **APLICADO AL ÁREA DE INGENIERÍA DE SISTEMAS**",
        "### 🏫 **UNIVERSIDAD PERUANA UNIÓN (UPEU)**",
        "",
        "</div>",
        "",
        "---",
        "",
        "## 📋 **INFORMACIÓN COMPLETA DEL PROYECTO**",
        "",
        "<div align=\"center\">",
        "",
        "| **🔍 Campo** | **📊 Detalle** |",
        "|:-------------|:---------------|",
        "| **👨‍💻 Autor** | **[Tu Nombre Completo]** |",
        "| **📅 Fecha** | **Septiembre 2025** |",
        "| **🏫 Universidad** | **Universidad Peruana Unión (UPEU)** |",
        "| **📚 Curso** | **Business Intelligence** |",
        "| **👨‍🏫 Docente** | **[Nombre del Profesor]** |",
        "| **📊 Dataset** | **Kaggle ML & Data Science Survey 2019** |",
        "| **🎯 Aplicación** | **Ingeniería de Sistemas** |",
        "| **⏰ Tiempo Documentación** | **30-50 horas académicas** |",
        "| **🔧 Herramientas Principales** | **Python, Pandas, Matplotlib, Seaborn, Plotly** |",
        "| **✅ Validación** | **Power BI, Excel, CSV** |",
        "| **📈 Registros Procesados** | **19,717 profesionales** |",
        "| **🌍 Cobertura Geográfica** | **171 países** |",
        "",
        "</div>",
        "",
        "---",
        "",
        "## 🎯 **OBJETIVOS ESTRATÉGICOS DEL PROYECTO**",
        "",
        "<div align=\"center\">",
        "",
        "### 🚀 **OBJETIVOS PRINCIPALES**",
        "",
        "</div>",
        "",
        "| **#** | **🎯 Objetivo** | **📊 Descripción** | **⏰ Tiempo** |",
        "|:-----:|:---------------|:-------------------|:-------------|",
        "| **1** | **🔄 Proceso ETL Robusto** | Implementar extracción, transformación y carga optimizada | **15-20h** |",
        "| **2** | **📈 Análisis Tecnológico** | Identificar tendencias para Ingeniería de Sistemas | **10-15h** |",
        "| **3** | **✅ Validación Cruzada** | Comparar resultados Python vs Power BI | **5-8h** |",
        "| **4** | **💡 Insights Accionables** | Generar recomendaciones basadas en datos | **8-12h** |",
        "| **5** | **📚 Documentación Académica** | Crear documentación profesional completa | **10-15h** |",
        "",
        "### 🔍 **OBJETIVOS ESPECÍFICOS PARA INGENIERÍA DE SISTEMAS**",
        "",
        "- **🏗️ Arquitectura**: Analizar adopción de tecnologías cloud (AWS, Azure, GCP)",
        "- **💻 Desarrollo**: Identificar lenguajes y frameworks más demandados",
        "- **🔧 Herramientas**: Evaluar IDEs, bases de datos y herramientas DevOps",
        "- **💰 Mercado Laboral**: Analizar salarios y oportunidades por tecnología",
        "- **📊 Toma de Decisiones**: Proporcionar datos para decisiones tecnológicas",
        "",
        "---",
        "",
        "## 🗂️ **ESTRUCTURA COMPLETA DEL NOTEBOOK**",
        "",
        "<div align=\"center\">",
        "",
        "### 📚 **ROADMAP DE DOCUMENTACIÓN (30-50 HORAS)**",
        "",
        "</div>",
        "",
        "| **📝 Sección** | **🔍 Descripción Detallada** | **⏰ Tiempo** | **📊 Entregables** |",
        "|:---------------|:------------------------------|:-------------|:-------------------|",
        "| **[1. Configuración](#1-configuración-del-entorno)** | Setup completo del entorno Python | **2-3h** | Librerías, configuración |",
        "| **[2. Extracción](#2-extracción-de-datos)** | Carga y validación del dataset | **4-6h** | Dataset cargado, validado |",
        "| **[3. EDA](#3-análisis-exploratorio)** | Análisis exploratorio exhaustivo | **8-12h** | Estadísticas, visualizaciones |",
        "| **[4. Transformación](#4-limpieza-y-transformación)** | Limpieza y procesamiento avanzado | **10-15h** | Datos limpios, normalizados |",
        "| **[5. Carga](#5-carga-de-datos)** | Exportación y validación | **3-5h** | CSV, Excel, metadatos |",
        "| **[6. Power BI](#6-validación-power-bi)** | Validación cruzada | **4-6h** | Scripts M, métricas |",
        "| **[7. Análisis](#7-análisis-de-resultados)** | Insights y visualizaciones | **6-10h** | Dashboards, reportes |",
        "| **[8. Conclusiones](#8-conclusiones)** | Síntesis y recomendaciones | **2-4h** | Reporte ejecutivo |",
        "",
        "<div align=\"center\">",
        "",
        "**🏆 TOTAL: 39-61 HORAS ACADÉMICAS**",
        "",
        "</div>",
        "",
        "---",
        "",
        "## 🌟 **RELEVANCIA CRÍTICA PARA INGENIERÍA DE SISTEMAS**",
        "",
        "### 🎯 **¿Por qué este Dataset es FUNDAMENTAL para Ingeniería de Sistemas?**",
        "",
        "<div align=\"center\">",
        "",
        "**El Kaggle ML & Data Science Survey 2019 contiene información de 19,717 profesionales de 171 países, proporcionando insights únicos sobre el ecosistema tecnológico global.**",
        "",
        "</div>",
        "",
        "---",
        "",
        "### 🏗️ **INFRAESTRUCTURA Y ARQUITECTURA DE SISTEMAS**",
        "",
        "| **🔧 Categoría** | **📊 Datos Disponibles** | **💡 Aplicación en Ing. Sistemas** |",
        "|:-----------------|:-------------------------|:------------------------------------|",
        "| **☁️ Cloud Platforms** | AWS, Azure, GCP, adoption rates | Selección de plataforma cloud óptima |",
        "| **🗄️ Databases** | SQL, NoSQL, NewSQL trends | Arquitectura de datos escalable |",
        "| **⚡ Big Data** | Spark, Hadoop, Kafka usage | Pipeline de procesamiento masivo |",
        "| **🐳 Containers** | Docker, Kubernetes adoption | Estrategias de containerización |",
        "| **🔄 MLOps** | ML deployment, monitoring | Infraestructura de ML en producción |",
        "",
        "### 💻 **DESARROLLO DE SOFTWARE Y DEVOPS**",
        "",
        "| **🛠️ Categoría** | **📈 Métricas Disponibles** | **🎯 Impacto Estratégico** |",
        "|:-----------------|:----------------------------|:---------------------------|",
        "| **🐍 Languages** | Python, R, Java, Scala popularity | Stack tecnológico optimal |",
        "| **💡 IDEs** | Jupyter, PyCharm, VS Code usage | Herramientas de desarrollo |",
        "| **📚 Frameworks** | TensorFlow, PyTorch, Scikit-learn | Selección de frameworks ML |",
        "| **🔄 Version Control** | Git, GitHub, GitLab adoption | Workflows de desarrollo |",
        "| **🚀 CI/CD** | Jenkins, GitHub Actions usage | Automatización de despliegues |",
        "",
        "### 📊 **ANÁLISIS DE MERCADO LABORAL TECNOLÓGICO**",
        "",
        "| **💼 Aspecto** | **📋 Información** | **🎯 Decisiones Estratégicas** |",
        "|:---------------|:-------------------|:-------------------------------|",
        "| **💰 Salarios** | Compensación por tecnología | ROI de capacitación técnica |",
        "| **🌍 Geografía** | Distribución global de talento | Estrategias de contratación |",
        "| **🎓 Educación** | Niveles y áreas de formación | Programas de desarrollo |",
        "| **📈 Trends** | Tecnologías emergentes | Roadmap tecnológico |",
        "| **👥 Demographics** | Diversidad y experiencia | Gestión de equipos |",
        "",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "",
        "# 1. CONFIGURACIÓN DEL ENTORNO",
        "",
        "<div align=\"center\">",
        "<img src=\"https://img.shields.io/badge/Phase-1%2F8-blue?style=for-the-badge\" alt=\"Phase 1\">",
        "<img src=\"https://img.shields.io/badge/Time-2--3h-orange?style=for-the-badge\" alt=\"Time\">",
        "<img src=\"https://img.shields.io/badge/Status-🔧_Setup-yellow?style=for-the-badge\" alt=\"Status\">",
        "</div>",
        "",
        "## 📦 **Instalación Completa de Dependencias**",
        "",
        "Esta sección establece el entorno completo de trabajo para el proceso ETL. Instalamos y configuramos todas las librerías necesarias para análisis de datos profesional.",
        "",
        "### 🔧 **Stack Tecnológico Completo**",
        "",
        "| **📚 Categoría** | **🛠️ Librerías** | **🎯 Propósito** |",
        "|:-----------------|:------------------|:------------------|",
        "| **📊 Data Analysis** | `pandas`, `numpy` | Manipulación y análisis de datos |",
        "| **📈 Visualization** | `matplotlib`, `seaborn`, `plotly` | Visualizaciones estáticas e interactivas |",
        "| **🤖 Machine Learning** | `scikit-learn`, `scipy` | Preprocessing y análisis estadístico |",
        "| **📄 File Handling** | `openpyxl`, `xlsxwriter` | Manejo de archivos Excel |",
        "| **🔧 Utilities** | `datetime`, `os`, `glob`, `json` | Utilidades del sistema |",
        "",
        "### 💡 **Configuración Profesional**",
        "- Estilos de visualización optimizados",
        "- Configuración de memoria eficiente",
        "- Supresión inteligente de warnings",
        "- Paletas de colores profesionales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📦 INSTALACIÓN Y VERIFICACIÓN COMPLETA DE DEPENDENCIAS",
        "print(\"🚀 CONFIGURACIÓN PROFESIONAL DEL ENTORNO ETL\")",
        "print(\"=\"*80)",
        "print(f\"⏰ Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")",
        "",
        "# === INSTALACIÓN DE DEPENDENCIAS ===",
        "# Descomenta la siguiente línea si necesitas instalar las librerías",
        "# !pip install pandas numpy matplotlib seaborn plotly openpyxl scikit-learn scipy xlsxwriter jupyter",
        "",
        "# === VERIFICACIÓN SISTEMÁTICA DE LIBRERÍAS ===",
        "print(\"\\n🔍 VERIFICACIÓN DE DEPENDENCIAS\")",
        "print(\"-\"*50)",
        "",
        "import sys",
        "import subprocess",
        "",
        "def verificar_e_importar(nombre_libreria, alias=None):",
        "    \"\"\"Verifica e importa una librería con manejo de errores\"\"\"",
        "    try:",
        "        if alias:",
        "            exec(f\"import {nombre_libreria} as {alias}\", globals())",
        "            version = eval(f\"{alias}.__version__\" if hasattr(eval(alias), '__version__') else \"None\")",
        "        else:",
        "            exec(f\"import {nombre_libreria}\", globals())",
        "            version = eval(f\"{nombre_libreria}.__version__\" if hasattr(eval(nombre_libreria), '__version__') else \"None\")",
        "        ",
        "        version_str = f\"v{version}\" if version else \"OK\"",
        "        print(f\"   ✅ {nombre_libreria:<15} {version_str}\")",
        "        return True",
        "    except ImportError as e:",
        "        print(f\"   ❌ {nombre_libreria:<15} NO DISPONIBLE\")",
        "        return False",
        "    except Exception as e:",
        "        print(f\"   ⚠️ {nombre_libreria:<15} ERROR: {str(e)[:30]}...\")",
        "        return False",
        "",
        "# Lista de librerías críticas",
        "librerias_criticas = [",
        "    ('pandas', 'pd'),",
        "    ('numpy', 'np'), ",
        "    ('matplotlib.pyplot', 'plt'),",
        "    ('seaborn', 'sns'),",
        "    ('plotly.express', 'px'),",
        "    ('plotly.graph_objects', 'go'),",
        "    ('sklearn', None),",
        "    ('scipy', None),",
        "    ('openpyxl', None)",
        "]",
        "",
        "# Verificar cada librería",
        "todas_disponibles = True",
        "for lib, alias in librerias_criticas:",
        "    if not verificar_e_importar(lib, alias):",
        "        todas_disponibles = False",
        "",
        "# === IMPORTACIÓN DE LIBRERÍAS DEL SISTEMA ===",
        "print(\"\\n📁 LIBRERÍAS DEL SISTEMA:\")",
        "import os",
        "import glob",
        "import json",
        "import re",
        "import warnings",
        "from datetime import datetime, timedelta",
        "",
        "print(\"   ✅ os, glob, json, re, warnings, datetime\")",
        "",
        "if todas_disponibles:",
        "    print(\"\\n🎉 TODAS LAS DEPENDENCIAS VERIFICADAS CORRECTAMENTE\")",
        "else:",
        "    print(\"\\n⚠️ ALGUNAS DEPENDENCIAS NO ESTÁN DISPONIBLES\")",
        "    print(\"💡 Ejecutar: pip install pandas numpy matplotlib seaborn plotly scikit-learn openpyxl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎨 CONFIGURACIÓN PROFESIONAL DE VISUALIZACIONES Y ENTORNO",
        "print(\"\\n🎨 CONFIGURACIÓN PROFESIONAL DE VISUALIZACIONES\")",
        "print(\"-\"*50)",
        "",
        "# === CONFIGURACIÓN AVANZADA DE MATPLOTLIB ===",
        "if 'plt' in globals():",
        "    # Estilo profesional",
        "    plt.style.use('seaborn-v0_8-darkgrid')",
        "    ",
        "    # Configuración detallada",
        "    configuracion_matplotlib = {",
        "        'figure.figsize': (16, 10),",
        "        'font.size': 12,",
        "        'axes.titlesize': 18,",
        "        'axes.labelsize': 14,",
        "        'xtick.labelsize': 12,",
        "        'ytick.labelsize': 12,",
        "        'legend.fontsize': 12,",
        "        'figure.titlesize': 20,",
        "        'axes.grid': True,",
        "        'grid.alpha': 0.3,",
        "        'axes.spines.top': False,",
        "        'axes.spines.right': False,",
        "        'figure.facecolor': 'white',",
        "        'axes.facecolor': 'white'",
        "    }",
        "    ",
        "    plt.rcParams.update(configuracion_matplotlib)",
        "    print(\"   ✅ Matplotlib configurado con estilo profesional\")",
        "",
        "# === PALETA DE COLORES PROFESIONAL ===",
        "if 'sns' in globals():",
        "    # Paleta corporativa moderna",
        "    colores_profesionales = [",
        "        '#2E86AB',  # Azul principal",
        "        '#A23B72',  # Magenta",
        "        '#F18F01',  # Naranja",
        "        '#C73E1D',  # Rojo",
        "        '#592E83',  # Púrpura",
        "        '#F79824',  # Amarillo",
        "        '#3F88C5',  # Azul claro",
        "        '#032B43'   # Azul oscuro",
        "    ]",
        "    ",
        "    sns.set_palette(colores_profesionales)",
        "    print(\"   ✅ Seaborn configurado con paleta corporativa\")",
        "",
        "# === CONFIGURACIÓN AVANZADA DE PANDAS ===",
        "if 'pd' in globals():",
        "    configuracion_pandas = {",
        "        'display.max_columns': None,",
        "        'display.width': None,",
        "        'display.max_colwidth': 100,",
        "        'display.precision': 2,",
        "        'display.float_format': '{:.2f}'.format,",
        "        'display.max_rows': 50,",
        "        'display.min_rows': 20,",
        "        'display.show_dimensions': True",
        "    }",
        "    ",
        "    for opcion, valor in configuracion_pandas.items():",
        "        pd.set_option(opcion, valor)",
        "    ",
        "    print(\"   ✅ Pandas configurado para análisis profesional\")",
        "",
        "# === CONFIGURACIÓN DE PLOTLY ===",
        "if 'px' in globals():",
        "    # Configuración para notebooks",
        "    import plotly.offline as pyo",
        "    pyo.init_notebook_mode(connected=True)",
        "    ",
        "    # Template profesional",
        "    import plotly.io as pio",
        "    pio.templates.default = \"plotly_white\"",
        "    ",
        "    print(\"   ✅ Plotly configurado para visualizaciones interactivas\")",
        "",
        "# === SUPRESIÓN INTELIGENTE DE WARNINGS ===",
        "warnings.filterwarnings('ignore', category=FutureWarning)",
        "warnings.filterwarnings('ignore', category=UserWarning)",
        "warnings.filterwarnings('ignore', message='.*dtype.*')",
        "print(\"   ✅ Warnings optimizados para análisis limpio\")",
        "",
        "# === INFORMACIÓN DEL SISTEMA ===",
        "print(\"\\n💻 INFORMACIÓN DEL SISTEMA\")",
        "print(\"-\"*50)",
        "print(f\"   🐍 Python: {sys.version.split()[0]}\")",
        "if 'pd' in globals():",
        "    print(f\"   🐼 Pandas: {pd.__version__}\")",
        "if 'np' in globals():",
        "    print(f\"   🔢 NumPy: {np.__version__}\")",
        "if 'plt' in globals():",
        "    print(f\"   📊 Matplotlib: {plt.matplotlib.__version__}\")",
        "if 'sns' in globals():",
        "    print(f\"   📈 Seaborn: {sns.__version__}\")",
        "",
        "# Información de memoria si está disponible",
        "try:",
        "    import psutil",
        "    memoria = psutil.virtual_memory()",
        "    print(f\"   💾 RAM Total: {memoria.total / 1024**3:.1f} GB\")",
        "    print(f\"   💾 RAM Disponible: {memoria.available / 1024**3:.1f} GB\")",
        "except ImportError:",
        "    print(\"   💾 Información de memoria no disponible\")",
        "",
        "print(\"\\n✅ CONFIGURACIÓN COMPLETA DEL ENTORNO FINALIZADA\")",
        "print(\"🚀 Sistema listo para proceso ETL profesional\")",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---",
        "",
        "# 2. EXTRACCIÓN DE DATOS",
        "",
        "<div align=\"center\">",
        "<img src=\"https://img.shields.io/badge/Phase-2%2F8-blue?style=for-the-badge\" alt=\"Phase 2\">",
        "<img src=\"https://img.shields.io/badge/Time-4--6h-orange?style=for-the-badge\" alt=\"Time\">",
        "<img src=\"https://img.shields.io/badge/Status-📊_Extract-green?style=for-the-badge\" alt=\"Status\">",
        "</div>",
        "",
        "## 📊 **Dataset: Kaggle ML & Data Science Survey 2019**",
        "",
        "### 🌍 **Descripción Completa del Dataset**",
        "",
        "El **Kaggle Machine Learning & Data Science Survey 2019** es la encuesta anual más comprehensiva del ecosistema de Data Science y Machine Learning a nivel mundial.",
        "",
        "<div align=\"center\">",
        "",
        "### 📈 **ESTADÍSTICAS CLAVE DEL DATASET**",
        "",
        "</div>",
        "",
        "| **📊 Métrica** | **🔢 Valor** | **📋 Descripción** |",
        "|:---------------|:-------------|:-------------------|",
        "| **👥 Participantes** | **19,717** | Profesionales de DS/ML |",
        "| **🌍 Países** | **171** | Cobertura global |",
        "| **❓ Preguntas** | **50+** | Temas diversos |",
        "| **📊 Variables** | **395** | Columnas de datos |",
        "| **📅 Año** | **2019** | Snapshot temporal |",
        "| **🏢 Organización** | **Kaggle (Google)** | Plataforma líder |",
        "| **📄 Formato** | **CSV** | Datos estructurados |",
        "| **💾 Tamaño** | **~40 MB** | Dataset manejable |",
        "",
        "---",
        "",
        "## 🎯 **RELEVANCIA ESTRATÉGICA PARA INGENIERÍA DE SISTEMAS**",
        "",
        "### 🏗️ **1. ARQUITECTURA E INFRAESTRUCTURA**",
        "",
        "#### ☁️ **Cloud Computing & Infrastructure**",
        "- **Plataformas**: AWS, Microsoft Azure, Google Cloud Platform",
        "- **Servicios**: EC2, S3, Lambda, Azure Functions, BigQuery",
        "- **Tendencias**: Migración a la nube, arquitecturas serverless",
        "- **Costos**: Análisis ROI por plataforma",
        "",
        "#### 🗄️ **Sistemas de Bases de Datos**",
        "- **SQL**: MySQL, PostgreSQL, SQL Server, Oracle",
        "- **NoSQL**: MongoDB, Cassandra, Redis, DynamoDB",
        "- **Big Data**: Hadoop, Spark, Elasticsearch, Kafka",
        "- **Data Warehouses**: Snowflake, Redshift, BigQuery",
        "",
        "### 💻 **2. DESARROLLO DE SOFTWARE**",
        "",
        "#### 🐍 **Lenguajes de Programación**",
        "- **Data Science**: Python dominance, R for statistics",
        "- **Enterprise**: Java, Scala for distributed systems  ",
        "- **Web**: JavaScript, TypeScript for interfaces",
        "- **Systems**: C++, Go for performance-critical applications",
        "",
        "#### 🛠️ **Herramientas de Desarrollo**",
        "- **IDEs**: Jupyter Notebooks, PyCharm, VS Code, RStudio",
        "- **Version Control**: Git, GitHub, GitLab, Bitbucket",
        "- **CI/CD**: Jenkins, GitHub Actions, Azure DevOps",
        "- **Containers**: Docker, Kubernetes, OpenShift",
        "",
        "### 📊 **3. ANÁLISIS DE MERCADO TECNOLÓGICO**",
        "",
        "#### 💰 **Compensación y ROI**",
        "- **Salarios por tecnología**: Python, R, Java, Scala",
        "- **Premiums**: Cloud skills, ML expertise, Big Data",
        "- **Geografía**: Silicon Valley, NYC, London, Bangalore",
        "- **Experiencia**: Junior vs Senior compensation curves",
        "",
        "#### 🎓 **Educación y Capacitación**",
        "- **Formal Education**: CS, Math, Engineering, Physics",
        "- **Online Learning**: Coursera, Udacity, edX, Kaggle Learn",
        "- **Bootcamps**: Intensive training programs",
        "- **Certifications**: AWS, Azure, Google Cloud, vendor-specific",
        "",
        "---",
        "",
        "## 🔍 **APLICACIONES DIRECTAS EN INGENIERÍA DE SISTEMAS**",
        "",
        "### 1. **🏗️ Planificación de Arquitecturas**",
        "- **Technology Stack Selection**: Basado en adopción y madurez",
        "- **Scalability Planning**: Herramientas para sistemas distribuidos",
        "- **Performance Optimization**: Lenguajes y frameworks óptimos",
        "",
        "### 2. **👥 Gestión de Equipos Técnicos**",
        "- **Hiring Strategy**: Skills más demandados y mejor pagados",
        "- **Training Programs**: Capacitación basada en tendencias",
        "- **Retention**: Compensación competitiva por especialización",
        "",
        "### 3. **🚀 Roadmap Tecnológico**",
        "- **Emerging Technologies**: Identificar tendencias tempranas",
        "- **Migration Planning**: Timing óptimo para adopción",
        "- **Risk Assessment**: Madurez y estabilidad de tecnologías",
        "",
        "### 4. **📈 Business Intelligence**",
        "- **Market Research**: Competencia y positioning",
        "- **Investment Decisions**: ROI de capacitación e infraestructura",
        "- **Strategic Planning**: Alineación con tendencias del mercado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 PROCESO COMPLETO DE EXTRACCIÓN DE DATOS",
        "print(\"📊 EXTRACCIÓN PROFESIONAL DE DATOS - KAGGLE SURVEY 2019\")",
        "print(\"=\"*80)",
        "print(f\"🕐 Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")",
        "",
        "# === PASO 1: DIAGNÓSTICO DEL ENTORNO ===",
        "print(\"\\n🔍 PASO 1: DIAGNÓSTICO COMPLETO DEL ENTORNO\")",
        "print(\"-\"*60)",
        "",
        "# Directorio actual",
        "directorio_trabajo = os.getcwd()",
        "print(f\"📂 Directorio de trabajo: {directorio_trabajo}\")",
        "",
        "# Espacio en disco",
        "try:",
        "    import shutil",
        "    total, usado, libre = shutil.disk_usage(directorio_trabajo)",
        "    print(f\"💾 Espacio en disco:\")",
        "    print(f\"   • Total: {total / 1024**3:.2f} GB\")",
        "    print(f\"   • Usado: {usado / 1024**3:.2f} GB\") ",
        "    print(f\"   • Libre: {libre / 1024**3:.2f} GB\")",
        "    print(f\"   • Uso: {(usado/total)*100:.1f}%\")",
        "except:",
        "    print(\"💾 Información de disco no disponible\")",
        "",
        "# Inventario completo de archivos",
        "print(f\"\\n📋 INVENTARIO COMPLETO DE ARCHIVOS\")",
        "print(\"-\"*40)",
        "",
        "tipos_archivo = {",
        "    'CSV': '*.csv',",
        "    'Excel': '*.xlsx', ",
        "    'Texto': '*.txt',",
        "    'Python': '*.py',",
        "    'Jupyter': '*.ipynb',",
        "    'Markdown': '*.md',",
        "    'JSON': '*.json'",
        "}",
        "",
        "inventario_total = {}",
        "tamaño_total_mb = 0",
        "",
        "for tipo, patron in tipos_archivo.items():",
        "    archivos = glob.glob(patron)",
        "    if archivos:",
        "        print(f\"\\n📄 {tipo} Files ({len(archivos)}):\")",
        "        tamaño_tipo = 0",
        "        for archivo in archivos[:5]:  # Mostrar máximo 5 por tipo",
        "            try:",
        "                tamaño = os.path.getsize(archivo)",
        "                tamaño_tipo += tamaño",
        "                fecha = datetime.fromtimestamp(os.path.getmtime(archivo))",
        "                ",
        "                if tamaño > 1024**2:",
        "                    tamaño_str = f\"{tamaño/1024**2:.1f}MB\"",
        "                elif tamaño > 1024:",
        "                    tamaño_str = f\"{tamaño/1024:.1f}KB\" ",
        "                else:",
        "                    tamaño_str = f\"{tamaño}B\"",
        "                    ",
        "                print(f\"   • {archivo:<35} {tamaño_str:>8} {fecha.strftime('%Y-%m-%d')}\")",
        "            except:",
        "                print(f\"   • {archivo:<35} {'ERROR':>8}\")",
        "        ",
        "        if len(archivos) > 5:",
        "            print(f\"   ... y {len(archivos) - 5} archivos más\")",
        "            ",
        "        tamaño_total_mb += tamaño_tipo",
        "        print(f\"   📊 Subtotal: {tamaño_tipo/1024**2:.2f} MB\")",
        "    ",
        "    inventario_total[tipo] = archivos",
        "",
        "print(f\"\\n📊 RESUMEN DEL INVENTARIO:\")",
        "total_archivos = sum(len(archivos) for archivos in inventario_total.values())",
        "print(f\"   • Archivos totales: {total_archivos}\")",
        "print(f\"   • Tamaño total: {tamaño_total_mb/1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === PASO 2: IDENTIFICACIÓN Y VALIDACIÓN DEL DATASET PRINCIPAL ===",
        "print(f\"\\n🎯 PASO 2: IDENTIFICACIÓN DEL DATASET PRINCIPAL\")",
        "print(\"-\"*60)",
        "",
        "archivo_principal = \"multipleChoiceResponses.csv\"",
        "print(f\"🔍 Buscando archivo: {archivo_principal}\")",
        "",
        "if os.path.exists(archivo_principal):",
        "    print(f\"✅ Archivo encontrado: {archivo_principal}\")",
        "    ",
        "    # === ANÁLISIS DETALLADO DEL ARCHIVO ===",
        "    print(f\"\\n📊 ANÁLISIS DETALLADO DEL ARCHIVO\")",
        "    print(\"-\"*40)",
        "    ",
        "    # Información básica del archivo",
        "    stat_info = os.stat(archivo_principal)",
        "    tamaño_bytes = stat_info.st_size",
        "    fecha_creacion = datetime.fromtimestamp(stat_info.st_ctime)",
        "    fecha_modificacion = datetime.fromtimestamp(stat_info.st_mtime)",
        "    fecha_acceso = datetime.fromtimestamp(stat_info.st_atime)",
        "    ",
        "    print(f\"📁 Información del archivo:\")",
        "    print(f\"   • Nombre: {archivo_principal}\")",
        "    print(f\"   • Tamaño: {tamaño_bytes:,} bytes ({tamaño_bytes/1024**2:.2f} MB)\")",
        "    print(f\"   • Creado: {fecha_creacion.strftime('%Y-%m-%d %H:%M:%S')}\")",
        "    print(f\"   • Modificado: {fecha_modificacion.strftime('%Y-%m-%d %H:%M:%S')}\")",
        "    print(f\"   • Último acceso: {fecha_acceso.strftime('%Y-%m-%d %H:%M:%S')}\")",
        "    ",
        "    # Verificar permisos",
        "    permisos = []",
        "    if os.access(archivo_principal, os.R_OK):",
        "        permisos.append(\"✅ Lectura\")",
        "    else:",
        "        permisos.append(\"❌ Lectura\")",
        "        ",
        "    if os.access(archivo_principal, os.W_OK):",
        "        permisos.append(\"✅ Escritura\")",
        "    else:",
        "        permisos.append(\"⚠️ Escritura\")",
        "        ",
        "    print(f\"   • Permisos: {' | '.join(permisos)}\")",
        "    ",
        "    # === ANÁLISIS PRELIMINAR DE ESTRUCTURA ===",
        "    print(f\"\\n🔍 ANÁLISIS PRELIMINAR DE ESTRUCTURA\")",
        "    print(\"-\"*40)",
        "    ",
        "    try:",
        "        print(\"⏳ Analizando estructura del archivo...\")",
        "        ",
        "        # Leer muestra pequeña para análisis",
        "        muestra_inicial = pd.read_csv(archivo_principal, nrows=5, encoding='utf-8')",
        "        ",
        "        print(f\"✅ Estructura analizada exitosamente\")",
        "        print(f\"\\n📊 ESTRUCTURA DETECTADA:\")",
        "        print(f\"   • Columnas: {muestra_inicial.shape[1]}\")",
        "        print(f\"   • Filas de muestra: {muestra_inicial.shape[0]}\")",
        "        ",
        "        # Mostrar primeras columnas",
        "        print(f\"\\n🔤 PRIMERAS 15 COLUMNAS:\")",
        "        for i, columna in enumerate(muestra_inicial.columns[:15]):",
        "            # Truncar nombres largos",
        "            nombre_display = columna[:50] + \"...\" if len(columna) > 50 else columna",
        "            print(f\"   {i+1:2d}. {nombre_display}\")",
        "            ",
        "        if muestra_inicial.shape[1] > 15:",
        "            print(f\"   ... y {muestra_inicial.shape[1] - 15} columnas adicionales\")",
        "        ",
        "        # Análisis de tipos de datos",
        "        print(f\"\\n📋 TIPOS DE DATOS DETECTADOS:\")",
        "        tipos_detectados = muestra_inicial.dtypes.value_counts()",
        "        for tipo, cantidad in tipos_detectados.items():",
        "            print(f\"   • {str(tipo):15} {cantidad:3d} columnas\")",
        "            ",
        "        # Verificar encoding y separadores",
        "        print(f\"\\n🔧 CONFIGURACIÓN DETECTADA:\")",
        "        print(f\"   • Encoding: UTF-8 ✅\")",
        "        print(f\"   • Separador: Coma (,) ✅\") ",
        "        print(f\"   • Headers: Primera fila ✅\")",
        "        ",
        "        # Estimación de tiempo de carga",
        "        tiempo_estimado = (tamaño_bytes / 1024**2) * 0.5  # Aproximación",
        "        print(f\"   • Tiempo estimado de carga: {tiempo_estimado:.1f} segundos\")",
        "        ",
        "    except Exception as e:",
        "        print(f\"❌ Error en análisis preliminar: {str(e)}\")",
        "        print(\"💡 Posibles causas:\")",
        "        print(\"   • Formato de archivo incorrecto\")",
        "        print(\"   • Problemas de encoding\")",
        "        print(\"   • Archivo corrupto\")",
        "        ",
        "else:",
        "    print(f\"❌ Archivo no encontrado: {archivo_principal}\")",
        "    print(f\"\\n📋 Archivos CSV disponibles:\")",
        "    archivos_csv = glob.glob(\"*.csv\")",
        "    if archivos_csv:",
        "        for archivo in archivos_csv:",
        "            print(f\"   • {archivo}\")",
        "    else:",
        "        print(\"   • No se encontraron archivos CSV\")",
        "        ",
        "    print(f\"\\n💡 Sugerencias:\")",
        "    print(f\"   • Verificar nombre del archivo\")",
        "    print(f\"   • Descargar dataset desde Kaggle\")",
        "    print(f\"   • Revisar directorio de trabajo\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}