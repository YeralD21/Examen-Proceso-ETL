#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para Visualizar la Fase de TRANSFORMACI√ìN del Proceso ETL
Kaggle Survey 2019 - Ingenier√≠a de Sistemas

Este script muestra √∫nicamente la fase de transformaci√≥n con visualizaciones
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime

def verificar_archivo():
    """
    Verifica que el archivo CSV existe
    """
    archivo = "multipleChoiceResponses.csv"
    if not os.path.exists(archivo):
        print(f"‚ùå ERROR: No se encontr√≥ el archivo {archivo}")
        print("Aseg√∫rate de que el archivo est√© en el directorio actual")
        return False
    return True

def cargar_datos_originales():
    """
    Carga los datos originales para la transformaci√≥n
    """
    print("=" * 80)
    print("üöÄ FASE 2: TRANSFORMACI√ìN DE DATOS")
    print("=" * 80)
    
    archivo = "multipleChoiceResponses.csv"
    
    try:
        print(f"üìÅ Cargando dataset original desde: {archivo}")
        df = pd.read_csv(archivo, encoding='utf-8')
        
        print(f"‚úÖ Dataset original cargado")
        print(f"üìä Dimensiones originales: {df.shape}")
        
        return df
        
    except Exception as e:
        print(f"‚ùå Error al cargar el dataset: {str(e)}")
        return None

def mostrar_analisis_exploratorio(df):
    """
    FASE 2A: AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)
    """
    print("\n" + "=" * 80)
    print("üìä FASE 2A: AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)")
    print("=" * 80)
    
    # 1. Informaci√≥n general del dataset
    print("üìä 1. INFORMACI√ìN GENERAL DEL DATASET")
    print("-" * 50)
    print(f"Dimensiones: {df.shape}")
    print(f"Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    # 2. Tipos de datos
    print("\nüìã 2. TIPOS DE DATOS")
    print("-" * 50)
    tipos = df.dtypes.value_counts()
    for tipo, cantidad in tipos.items():
        print(f"   ‚Ä¢ {tipo}: {cantidad:,} columnas")
    
    # 3. Valores faltantes
    print("\n‚ùå 3. AN√ÅLISIS DE VALORES FALTANTES")
    print("-" * 50)
    missing_data = df.isnull().sum()
    missing_percentage = (missing_data / len(df)) * 100
    
    print(f"Total de columnas con valores faltantes: {(missing_data > 0).sum()}")
    print(f"Total de valores faltantes: {missing_data.sum():,}")
    print(f"Porcentaje promedio de valores faltantes: {missing_percentage.mean():.2f}%")
    
    # Mostrar las 10 columnas con m√°s valores faltantes
    missing_summary = pd.DataFrame({
        'Valores_Faltantes': missing_data,
        'Porcentaje': missing_percentage
    }).sort_values('Valores_Faltantes', ascending=False)
    
    print("\nüîù Top 10 columnas con m√°s valores faltantes:")
    for i, (col, row) in enumerate(missing_summary.head(10).iterrows(), 1):
        print(f"   {i:2d}. {col}: {row['Valores_Faltantes']:,} ({row['Porcentaje']:.1f}%)")
    
    # 4. Valores √∫nicos por columna
    print("\nüî¢ 4. AN√ÅLISIS DE VALORES √öNICOS")
    print("-" * 50)
    unique_counts = df.nunique()
    print(f"Columna con m√°s valores √∫nicos: {unique_counts.idxmax()} ({unique_counts.max()} valores)")
    print(f"Columna con menos valores √∫nicos: {unique_counts.idxmin()} ({unique_counts.min()} valores)")
    
    # 5. Registros duplicados
    print("\nüîÑ 5. AN√ÅLISIS DE REGISTROS DUPLICADOS")
    print("-" * 50)
    duplicates = df.duplicated().sum()
    print(f"Registros duplicados: {duplicates}")
    print(f"Porcentaje de duplicados: {(duplicates / len(df)) * 100:.2f}%")
    
    # 6. Estad√≠sticas descriptivas para columnas num√©ricas
    print("\nüìà 6. ESTAD√çSTICAS DESCRIPTIVAS (COLUMNAS NUM√âRICAS)")
    print("-" * 50)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        print(f"Columnas num√©ricas encontradas: {len(numeric_cols)}")
        print("\nEstad√≠sticas de la columna 'Time from Start to Finish (seconds)':")
        if 'Time from Start to Finish (seconds)' in df.columns:
            tiempo_col = pd.to_numeric(df['Time from Start to Finish (seconds)'], errors='coerce')
            print(f"   ‚Ä¢ Media: {tiempo_col.mean():.2f} segundos")
            print(f"   ‚Ä¢ Mediana: {tiempo_col.median():.2f} segundos")
            print(f"   ‚Ä¢ Desviaci√≥n est√°ndar: {tiempo_col.std():.2f} segundos")
            print(f"   ‚Ä¢ M√≠nimo: {tiempo_col.min():.2f} segundos")
            print(f"   ‚Ä¢ M√°ximo: {tiempo_col.max():.2f} segundos")
    else:
        print("No se encontraron columnas num√©ricas")
    
    # 7. An√°lisis de columnas categ√≥ricas principales
    print("\nüìä 7. AN√ÅLISIS DE COLUMNAS CATEG√ìRICAS PRINCIPALES")
    print("-" * 50)
    
    key_columns = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9']
    for col in key_columns:
        if col in df.columns:
            print(f"\n{col}:")
            value_counts = df[col].value_counts().head(5)
            for value, count in value_counts.items():
                percentage = (count / len(df)) * 100
                print(f"  ‚Ä¢ {value}: {count:,} ({percentage:.1f}%)")

def mostrar_limpieza_datos(df):
    """
    FASE 2B: LIMPIEZA Y TRANSFORMACI√ìN DE DATOS
    """
    print("\n" + "=" * 80)
    print("üßπ FASE 2B: LIMPIEZA Y TRANSFORMACI√ìN DE DATOS")
    print("=" * 80)
    
    df_clean = df.copy()
    print(f"üìä Dataset inicial: {df_clean.shape}")
    
    # 1. Eliminaci√≥n de registros duplicados
    print("\nüîÑ 1. ELIMINACI√ìN DE REGISTROS DUPLICADOS")
    print("-" * 50)
    initial_rows = len(df_clean)
    df_clean = df_clean.drop_duplicates()
    removed_duplicates = initial_rows - len(df_clean)
    print(f"Registros eliminados por duplicaci√≥n: {removed_duplicates}")
    print(f"Registros restantes: {len(df_clean):,}")
    
    # 2. Manejo de valores nulos
    print("\n‚ùå 2. MANEJO DE VALORES NULOS")
    print("-" * 50)
    
    # Estrategia: Para columnas con m√°s del 80% de valores faltantes, las eliminamos
    missing_percentage = (df_clean.isnull().sum() / len(df_clean)) * 100
    
    # Identificar columnas a eliminar
    columns_to_drop = missing_percentage[missing_percentage > 80].index
    print(f"Columnas identificadas para eliminar (>80% valores faltantes): {len(columns_to_drop)}")
    
    # Mostrar algunas columnas que se van a eliminar
    if len(columns_to_drop) > 0:
        print("\nüîù Ejemplos de columnas a eliminar:")
        for i, col in enumerate(columns_to_drop[:5], 1):
            porcentaje = missing_percentage[col]
            print(f"   {i}. {col}: {porcentaje:.1f}% valores faltantes")
    
    # Eliminar columnas con muchos valores faltantes
    df_clean = df_clean.drop(columns=columns_to_drop)
    print(f"Columnas eliminadas: {len(columns_to_drop)}")
    print(f"Columnas restantes: {df_clean.shape[1]}")
    
    # Para columnas categ√≥ricas, imputar con "No especificado"
    categorical_cols = df_clean.select_dtypes(include=['object']).columns
    print(f"\nImputando valores nulos en {len(categorical_cols)} columnas categ√≥ricas...")
    
    for col in categorical_cols:
        if df_clean[col].isnull().sum() > 0:
            df_clean[col] = df_clean[col].fillna('No especificado')
    
    # Para columnas num√©ricas, imputar con la mediana
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
    print(f"Imputando valores nulos en {len(numeric_cols)} columnas num√©ricas...")
    
    for col in numeric_cols:
        if df_clean[col].isnull().sum() > 0:
            df_clean[col] = df_clean[col].fillna(df_clean[col].median())
    
    print(f"Valores nulos restantes: {df_clean.isnull().sum().sum()}")
    
    # 3. Limpieza de espacios en blanco
    print("\nüßπ 3. LIMPIEZA DE ESPACIOS EN BLANCO")
    print("-" * 50)
    
    # Eliminar espacios al inicio y final de strings
    for col in categorical_cols:
        if col in df_clean.columns:
            df_clean[col] = df_clean[col].astype(str).str.strip()
    
    print("Espacios en blanco eliminados de todas las columnas de texto")
    
    # 4. Normalizaci√≥n de datos
    print("\nüîÑ 4. NORMALIZACI√ìN DE DATOS")
    print("-" * 50)
    
    # Normalizar texto a min√∫sculas para ciertas columnas
    text_columns = ['Q1_OTHER_TEXT', 'Q6_OTHER_TEXT', 'Q7_OTHER_TEXT', 'Q11_OTHER_TEXT']
    for col in text_columns:
        if col in df_clean.columns:
            df_clean[col] = df_clean[col].str.lower()
            print(f"Columna {col} normalizada a min√∫sculas")
    
    # 5. Conversi√≥n de tipos de datos
    print("\nüîÑ 5. CONVERSI√ìN DE TIPOS DE DATOS")
    print("-" * 50)
    
    # Convertir columna de tiempo a num√©rico
    if 'Time from Start to Finish (seconds)' in df_clean.columns:
        df_clean['Time from Start to Finish (seconds)'] = pd.to_numeric(
            df_clean['Time from Start to Finish (seconds)'], errors='coerce'
        )
        print("Columna 'Time from Start to Finish (seconds)' convertida a num√©rico")
    
    return df_clean

def mostrar_renombrado_columnas(df_clean):
    """
    FASE 2C: RENOMBRADO DE COLUMNAS
    """
    print("\n" + "=" * 80)
    print("üìù FASE 2C: RENOMBRADO DE COLUMNAS")
    print("=" * 80)
    
    # Crear mapeo de columnas
    column_mapping = {
        # Informaci√≥n general
        'Time from Start to Finish (seconds)': 'Tiempo_Total_Encuesta_Segundos',
        
        # Demograf√≠a y formaci√≥n
        'Q1': 'Edad_Encuestado',
        'Q1_OTHER_TEXT': 'Edad_Encuestado_Texto_Libre',
        'Q2': 'Genero',
        'Q3': 'Pais_Residencia',
        'Q4': 'Nivel_Educativo',
        'Q5': 'Area_Estudios_Principal',
        
        # Situaci√≥n laboral
        'Q6': 'Situacion_Laboral_Actual',
        'Q6_OTHER_TEXT': 'Situacion_Laboral_Texto_Libre',
        'Q7': 'Cargo_Principal_Trabajo',
        'Q7_OTHER_TEXT': 'Cargo_Principal_Texto_Libre',
        'Q8': 'Anos_Experiencia_Campo',
        'Q9': 'Rango_Salarial_Anual',
        
        # Lenguajes y herramientas
        'Q10': 'Lenguajes_Programacion_Habituales',
        'Q11_Part_1': 'IDE_Jupyter_IPython',
        'Q11_Part_2': 'IDE_RStudio',
        'Q11_Part_3': 'IDE_PyCharm',
        'Q11_Part_4': 'IDE_Visual_Studio_Code',
        'Q11_Part_5': 'IDE_nteract',
        'Q11_Part_6': 'IDE_Atom',
        'Q11_Part_7': 'IDE_MATLAB',
        'Q11_OTHER_TEXT': 'IDE_Otros_Texto_Libre',
        
        # Plataformas y hardware
        'Q12_MULTIPLE_CHOICE': 'Herramienta_Analisis_Datos_Principal',
        'Q12_Part_1_TEXT': 'Herramienta_Estadistica_Basica_Texto',
        'Q12_Part_2_TEXT': 'Herramienta_Estadistica_Avanzada_Texto',
        'Q12_Part_3_TEXT': 'Herramienta_BI_Texto',
        'Q12_Part_4_TEXT': 'Herramienta_Desarrollo_Local_Texto',
        'Q12_Part_5_TEXT': 'Herramienta_Cloud_APIs_Texto',
        'Q12_OTHER_TEXT': 'Herramienta_Analisis_Otros_Texto',
    }
    
    # Crear mapeo solo para columnas que existen en el dataset
    existing_mapping = {k: v for k, v in column_mapping.items() if k in df_clean.columns}
    
    print(f"üìù RENOMBRANDO {len(existing_mapping)} COLUMNAS")
    print("-" * 50)
    
    # Mostrar ejemplos de renombrado
    print("üîπ EJEMPLOS DE RENOMBRADO:")
    for i, (old_name, new_name) in enumerate(list(existing_mapping.items())[:10], 1):
        print(f"   {i:2d}. {old_name}")
        print(f"       ‚Üí {new_name}")
    
    if len(existing_mapping) > 10:
        print(f"   ... y {len(existing_mapping) - 10} columnas m√°s")
    
    # Aplicar renombrado
    df_renamed = df_clean.rename(columns=existing_mapping)
    
    print(f"\n‚úÖ RENOMBRADO COMPLETADO")
    print(f"üìä Columnas renombradas: {len(existing_mapping)}")
    
    return df_renamed

def mostrar_columnas_derivadas(df_renamed):
    """
    FASE 2D: CREACI√ìN DE COLUMNAS DERIVADAS
    """
    print("\n" + "=" * 80)
    print("‚ûï FASE 2D: CREACI√ìN DE COLUMNAS DERIVADAS")
    print("=" * 80)
    
    df_final = df_renamed.copy()
    
    # 1. Crear categor√≠a de experiencia
    print("üîπ 1. CREANDO CATEGOR√çA DE EXPERIENCIA")
    print("-" * 40)
    
    if 'Anos_Experiencia_Campo' in df_final.columns:
        def categorize_experience(exp):
            if pd.isna(exp) or exp == 'No especificado':
                return 'No especificado'
            elif exp in ['0-1', '1-2']:
                return 'Principiante (0-2 a√±os)'
            elif exp in ['2-3', '3-4']:
                return 'Intermedio (2-4 a√±os)'
            elif exp in ['4-5', '5-10']:
                return 'Avanzado (4-10 a√±os)'
            else:
                return 'Experto (10+ a√±os)'
        
        df_final['Categoria_Experiencia'] = df_final['Anos_Experiencia_Campo'].apply(categorize_experience)
        
        # Mostrar distribuci√≥n
        exp_dist = df_final['Categoria_Experiencia'].value_counts()
        print("Distribuci√≥n de categor√≠as de experiencia:")
        for categoria, count in exp_dist.items():
            percentage = (count / len(df_final)) * 100
            print(f"   ‚Ä¢ {categoria}: {count:,} ({percentage:.1f}%)")
    
    # 2. Crear categor√≠a de salario
    print("\nüîπ 2. CREANDO CATEGOR√çA DE SALARIO")
    print("-" * 40)
    
    if 'Rango_Salarial_Anual' in df_final.columns:
        def categorize_salary(salary):
            if pd.isna(salary) or salary in ['No especificado', 'I do not wish to disclose my approximate yearly compensation']:
                return 'No especificado'
            elif salary in ['0-10,000', '10-20,000']:
                return 'Bajo (0-20k)'
            elif salary in ['20-30,000', '30-40,000', '40-50,000']:
                return 'Medio (20-50k)'
            elif salary in ['50-60,000', '60-70,000', '70-80,000', '80-90,000', '90-100,000']:
                return 'Alto (50-100k)'
            else:
                return 'Muy Alto (100k+)'
        
        df_final['Categoria_Salarial'] = df_final['Rango_Salarial_Anual'].apply(categorize_salary)
        
        # Mostrar distribuci√≥n
        sal_dist = df_final['Categoria_Salarial'].value_counts()
        print("Distribuci√≥n de categor√≠as salariales:")
        for categoria, count in sal_dist.items():
            percentage = (count / len(df_final)) * 100
            print(f"   ‚Ä¢ {categoria}: {count:,} ({percentage:.1f}%)")
    
    print(f"\n‚úÖ COLUMNAS DERIVADAS CREADAS")
    print(f"üìä Total de columnas finales: {df_final.shape[1]}")
    
    return df_final

def mostrar_comparacion_antes_despues(df_original, df_final):
    """
    Muestra la comparaci√≥n antes y despu√©s de la transformaci√≥n
    """
    print("\n" + "=" * 80)
    print("üìä COMPARACI√ìN ANTES Y DESPU√âS DE LA TRANSFORMACI√ìN")
    print("=" * 80)
    
    print("üìà M√âTRICAS DE TRANSFORMACI√ìN:")
    print("-" * 40)
    print(f"Registros originales: {df_original.shape[0]:,}")
    print(f"Registros finales: {df_final.shape[0]:,}")
    print(f"Reducci√≥n de registros: {df_original.shape[0] - df_final.shape[0]:,}")
    
    print(f"\nColumnas originales: {df_original.shape[1]:,}")
    print(f"Columnas finales: {df_final.shape[1]:,}")
    print(f"Reducci√≥n de columnas: {df_original.shape[1] - df_final.shape[1]:,}")
    
    print(f"\nValores nulos originales: {df_original.isnull().sum().sum():,}")
    print(f"Valores nulos finales: {df_final.isnull().sum().sum():,}")
    print(f"Valores nulos eliminados: {df_original.isnull().sum().sum() - df_final.isnull().sum().sum():,}")
    
    print(f"\nMemoria original: {df_original.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    print(f"Memoria final: {df_final.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    print(f"Reducci√≥n de memoria: {((df_original.memory_usage(deep=True).sum() - df_final.memory_usage(deep=True).sum()) / df_original.memory_usage(deep=True).sum()) * 100:.1f}%")
    
    # Mostrar primeras filas del dataset transformado
    print("\nüìã PRIMERAS 5 FILAS DEL DATASET TRANSFORMADO:")
    print("-" * 50)
    
    # Seleccionar columnas principales para mostrar
    columnas_principales = [
        'Tiempo_Total_Encuesta_Segundos', 'Edad_Encuestado', 'Genero', 
        'Pais_Residencia', 'Nivel_Educativo', 'Categoria_Experiencia', 'Categoria_Salarial'
    ]
    
    columnas_existentes = [col for col in columnas_principales if col in df_final.columns]
    
    if columnas_existentes:
        df_muestra = df_final[columnas_existentes].head(5)
        print(df_muestra.to_string(index=True))
    else:
        print("No se encontraron las columnas principales transformadas")

def main():
    """
    Funci√≥n principal para ejecutar la visualizaci√≥n de transformaci√≥n
    """
    print("üöÄ VISUALIZACI√ìN DE LA FASE DE TRANSFORMACI√ìN")
    print("üìä Dataset: Kaggle Machine Learning & Data Science Survey 2019")
    print("üéØ Aplicaci√≥n: Ingenier√≠a de Sistemas")
    print("=" * 80)
    
    # Verificar archivo
    if not verificar_archivo():
        return
    
    # Cargar datos originales
    df_original = cargar_datos_originales()
    if df_original is None:
        return
    
    # Mostrar an√°lisis exploratorio
    mostrar_analisis_exploratorio(df_original)
    
    # Mostrar limpieza de datos
    df_clean = mostrar_limpieza_datos(df_original)
    
    # Mostrar renombrado de columnas
    df_renamed = mostrar_renombrado_columnas(df_clean)
    
    # Mostrar columnas derivadas
    df_final = mostrar_columnas_derivadas(df_renamed)
    
    # Mostrar comparaci√≥n antes y despu√©s
    mostrar_comparacion_antes_despues(df_original, df_final)
    
    print("\n" + "=" * 80)
    print("‚úÖ FASE DE TRANSFORMACI√ìN COMPLETADA")
    print("üìä Dataset transformado listo para la siguiente fase: CARGA")
    print("=" * 80)
    
    print("\nüéØ PR√ìXIMOS PASOS:")
    print("1. Ejecutar: python ver_carga_datos.py")
    print("2. O ejecutar todo: python ejecutar_proceso_completo.py")
    
    return df_final

if __name__ == "__main__":
    main()
