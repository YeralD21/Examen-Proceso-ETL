{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PROCESO ETL COMPLETO - KAGGLE SURVEY 2019\n",
        "## Aplicado al √Årea de Ingenier√≠a de Sistemas\n",
        "\n",
        "---\n",
        "\n",
        "### üìã **INFORMACI√ìN DEL PROYECTO**\n",
        "\n",
        "**Autor:** [Tu Nombre]  \n",
        "**Fecha:** Septiembre 2025  \n",
        "**Curso:** Business Intelligence - UPEU  \n",
        "**Dataset:** Kaggle Machine Learning & Data Science Survey 2019  \n",
        "**Aplicaci√≥n:** Ingenier√≠a de Sistemas  \n",
        "**Horas de Documentaci√≥n:** 30-50 horas  \n",
        "\n",
        "---\n",
        "\n",
        "### üéØ **OBJETIVOS DEL PROYECTO**\n",
        "\n",
        "1. **Implementar un proceso ETL robusto** y reproducible\n",
        "2. **Analizar tendencias tecnol√≥gicas** relevantes para Ingenier√≠a de Sistemas\n",
        "3. **Validar resultados** mediante comparaci√≥n con Power BI\n",
        "4. **Generar insights accionables** para la toma de decisiones tecnol√≥gicas\n",
        "5. **Documentar completamente** el proceso para fines acad√©micos\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **ESTRUCTURA DEL NOTEBOOK**\n",
        "\n",
        "1. **[1. Configuraci√≥n del Entorno](#1-configuraci√≥n-del-entorno)**\n",
        "2. **[2. Extracci√≥n de Datos](#2-extracci√≥n-de-datos)**\n",
        "3. **[3. An√°lisis Exploratorio de Datos (EDA)](#3-an√°lisis-exploratorio-de-datos-eda)**\n",
        "4. **[4. Limpieza y Transformaci√≥n](#4-limpieza-y-transformaci√≥n)**\n",
        "5. **[5. Carga de Datos](#5-carga-de-datos)**\n",
        "6. **[6. Validaci√≥n con Power BI](#6-validaci√≥n-con-power-bi)**\n",
        "7. **[7. An√°lisis de Resultados](#7-an√°lisis-de-resultados)**\n",
        "8. **[8. Conclusiones y Recomendaciones](#8-conclusiones-y-recomendaciones)**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. CONFIGURACI√ìN DEL ENTORNO\n",
        "\n",
        "### üì¶ **Instalaci√≥n de Dependencias**\n",
        "\n",
        "Primero, instalamos todas las librer√≠as necesarias para el proceso ETL:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalaci√≥n de dependencias (ejecutar solo si es necesario)\n",
        "# !pip install pandas numpy matplotlib seaborn plotly openpyxl jupyter\n",
        "\n",
        "print(\"üì¶ Dependencias instaladas correctamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìö **Importaci√≥n de Librer√≠as**\n",
        "\n",
        "Importamos todas las librer√≠as necesarias para el an√°lisis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librer√≠as principales para an√°lisis de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Librer√≠as para manejo de archivos y fechas\n",
        "import os\n",
        "import glob\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "\n",
        "# Configuraci√≥n de visualizaciones\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['axes.titlesize'] = 16\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "\n",
        "# Configuraci√≥n de pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# Suprimir warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
        "print(f\"üìÖ Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîß **Configuraci√≥n del Entorno**\n",
        "\n",
        "Configuramos el entorno de trabajo y verificamos los archivos disponibles:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar directorio de trabajo\n",
        "print(f\"üìÅ Directorio de trabajo: {os.getcwd()}\")\n",
        "\n",
        "# Verificar archivos disponibles\n",
        "archivos_csv = glob.glob(\"*.csv\")\n",
        "archivos_excel = glob.glob(\"*.xlsx\")\n",
        "archivos_txt = glob.glob(\"*.txt\")\n",
        "\n",
        "print(f\"\\nüìä Archivos encontrados:\")\n",
        "print(f\"   ‚Ä¢ Archivos CSV: {len(archivos_csv)}\")\n",
        "print(f\"   ‚Ä¢ Archivos Excel: {len(archivos_excel)}\")\n",
        "print(f\"   ‚Ä¢ Archivos TXT: {len(archivos_txt)}\")\n",
        "\n",
        "# Mostrar archivos principales\n",
        "if archivos_csv:\n",
        "    print(f\"\\nüìÑ Archivos CSV principales:\")\n",
        "    for archivo in archivos_csv[:5]:\n",
        "        tama√±o = os.path.getsize(archivo) / 1024 / 1024  # MB\n",
        "        print(f\"   ‚Ä¢ {archivo} ({tama√±o:.2f} MB)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. EXTRACCI√ìN DE DATOS\n",
        "\n",
        "### üìä **Descripci√≥n del Dataset**\n",
        "\n",
        "El dataset de **Kaggle Machine Learning & Data Science Survey 2019** es una encuesta global que recopila informaci√≥n de profesionales en el campo de la ciencia de datos y machine learning. Este dataset es altamente relevante para **Ingenier√≠a de Sistemas** porque:\n",
        "\n",
        "#### üèóÔ∏è **Infraestructura y Arquitectura:**\n",
        "- Contiene informaci√≥n sobre herramientas de desarrollo (IDEs, editores)\n",
        "- Datos sobre plataformas de computaci√≥n en la nube (AWS, Azure, GCP)\n",
        "- Informaci√≥n sobre bases de datos y sistemas de almacenamiento\n",
        "- Herramientas de big data y analytics\n",
        "\n",
        "#### üíª **Desarrollo de Software:**\n",
        "- Lenguajes de programaci√≥n m√°s utilizados en la industria\n",
        "- Frameworks y bibliotecas de machine learning\n",
        "- Herramientas de control de versiones y colaboraci√≥n\n",
        "- Metodolog√≠as de desarrollo y despliegue\n",
        "\n",
        "#### üîß **Herramientas y Tecnolog√≠as:**\n",
        "- IDEs y editores de c√≥digo preferidos\n",
        "- Plataformas de notebooks y desarrollo colaborativo\n",
        "- Herramientas de visualizaci√≥n de datos\n",
        "- Sistemas de bases de datos relacionales y NoSQL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìÅ **Carga del Dataset Original**\n",
        "\n",
        "Cargamos el dataset original desde el archivo CSV:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir el archivo de datos\n",
        "archivo_original = \"multipleChoiceResponses.csv\"\n",
        "\n",
        "# Verificar que el archivo existe\n",
        "if not os.path.exists(archivo_original):\n",
        "    print(f\"‚ùå Error: No se encontr√≥ el archivo {archivo_original}\")\n",
        "    print(\"Aseg√∫rate de que el archivo est√© en el directorio actual\")\n",
        "else:\n",
        "    print(f\"‚úÖ Archivo encontrado: {archivo_original}\")\n",
        "    \n",
        "    # Obtener informaci√≥n del archivo\n",
        "    tama√±o_archivo = os.path.getsize(archivo_original) / 1024 / 1024  # MB\n",
        "    print(f\"üìä Tama√±o del archivo: {tama√±o_archivo:.2f} MB\")\n",
        "    \n",
        "    # Cargar el dataset\n",
        "    print(\"\\n‚è≥ Cargando dataset... (esto puede tomar unos segundos)\")\n",
        "    \n",
        "    try:\n",
        "        # Cargar con configuraci√≥n optimizada\n",
        "        df_original = pd.read_csv(archivo_original, encoding='utf-8', low_memory=False)\n",
        "        \n",
        "        print(f\"‚úÖ Dataset cargado exitosamente\")\n",
        "        print(f\"üìä Dimensiones: {df_original.shape[0]:,} filas √ó {df_original.shape[1]:,} columnas\")\n",
        "        print(f\"üíæ Memoria utilizada: {df_original.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al cargar el dataset: {str(e)}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
