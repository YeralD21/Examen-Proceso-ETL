#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
An√°lisis y Visualizaciones para el Dataset de Kaggle Survey
Enfoque en Ingenier√≠a de Sistemas

Autor: [Tu Nombre]
Fecha: [Fecha Actual]
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
from datetime import datetime

warnings.filterwarnings('ignore')

# Configuraci√≥n para matplotlib
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['axes.labelsize'] = 14

class AnalisisVisualizaciones:
    """
    Clase para generar an√°lisis y visualizaciones del dataset de Kaggle Survey
    enfocado en Ingenier√≠a de Sistemas
    """
    
    def __init__(self, df_cleaned):
        """
        Inicializa la clase con el dataset limpio
        
        Args:
            df_cleaned (pd.DataFrame): Dataset limpio del proceso ETL
        """
        self.df = df_cleaned
        self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', 
                      '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
    
    def analisis_demografico(self):
        """
        An√°lisis demogr√°fico de los encuestados
        """
        print("üìä AN√ÅLISIS DEMOGR√ÅFICO")
        print("=" * 50)
        
        fig, axes = plt.subplots(2, 2, figsize=(20, 15))
        fig.suptitle('An√°lisis Demogr√°fico - Kaggle Survey 2019', fontsize=20, fontweight='bold')
        
        # 1. Distribuci√≥n por edad
        if 'Edad_Encuestado' in self.df.columns:
            age_counts = self.df['Edad_Encuestado'].value_counts()
            axes[0, 0].pie(age_counts.values, labels=age_counts.index, autopct='%1.1f%%', 
                          colors=self.colors[:len(age_counts)])
            axes[0, 0].set_title('Distribuci√≥n por Edad', fontweight='bold')
        
        # 2. Distribuci√≥n por g√©nero
        if 'Genero' in self.df.columns:
            gender_counts = self.df['Genero'].value_counts()
            axes[0, 1].bar(gender_counts.index, gender_counts.values, color=self.colors[:len(gender_counts)])
            axes[0, 1].set_title('Distribuci√≥n por G√©nero', fontweight='bold')
            axes[0, 1].set_ylabel('N√∫mero de Encuestados')
            axes[0, 1].tick_params(axis='x', rotation=45)
        
        # 3. Distribuci√≥n por nivel educativo
        if 'Nivel_Educativo' in self.df.columns:
            edu_counts = self.df['Nivel_Educativo'].value_counts()
            axes[1, 0].barh(edu_counts.index, edu_counts.values, color=self.colors[:len(edu_counts)])
            axes[1, 0].set_title('Distribuci√≥n por Nivel Educativo', fontweight='bold')
            axes[1, 0].set_xlabel('N√∫mero de Encuestados')
        
        # 4. Top 10 pa√≠ses
        if 'Pais_Residencia' in self.df.columns:
            country_counts = self.df['Pais_Residencia'].value_counts().head(10)
            axes[1, 1].barh(country_counts.index, country_counts.values, color=self.colors[:len(country_counts)])
            axes[1, 1].set_title('Top 10 Pa√≠ses', fontweight='bold')
            axes[1, 1].set_xlabel('N√∫mero de Encuestados')
        
        plt.tight_layout()
        plt.savefig('analisis_demografico.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas demogr√°ficas
        print(f"Total de encuestados: {len(self.df):,}")
        if 'Genero' in self.df.columns:
            print(f"Distribuci√≥n por g√©nero:")
            for gender, count in self.df['Genero'].value_counts().items():
                percentage = (count / len(self.df)) * 100
                print(f"  ‚Ä¢ {gender}: {count:,} ({percentage:.1f}%)")
    
    def analisis_lenguajes_programacion(self):
        """
        An√°lisis de lenguajes de programaci√≥n m√°s utilizados
        """
        print("\nüíª AN√ÅLISIS DE LENGUAJES DE PROGRAMACI√ìN")
        print("=" * 50)
        
        # Identificar columnas de lenguajes de programaci√≥n
        lang_columns = [col for col in self.df.columns if col.startswith('Lenguaje_') and col != 'Lenguaje_Otros_Texto_Libre']
        
        if not lang_columns:
            print("No se encontraron columnas de lenguajes de programaci√≥n")
            return
        
        # Contar uso de cada lenguaje
        lang_usage = {}
        for col in lang_columns:
            lang_name = col.replace('Lenguaje_', '').replace('_', ' ')
            count = self.df[col].notna().sum()
            lang_usage[lang_name] = count
        
        # Ordenar por uso
        lang_usage = dict(sorted(lang_usage.items(), key=lambda x: x[1], reverse=True))
        
        # Crear visualizaci√≥n
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
        fig.suptitle('An√°lisis de Lenguajes de Programaci√≥n', fontsize=18, fontweight='bold')
        
        # Gr√°fico de barras
        languages = list(lang_usage.keys())[:10]  # Top 10
        counts = list(lang_usage.values())[:10]
        
        bars = ax1.bar(languages, counts, color=self.colors[:len(languages)])
        ax1.set_title('Top 10 Lenguajes de Programaci√≥n', fontweight='bold')
        ax1.set_ylabel('N√∫mero de Usuarios')
        ax1.tick_params(axis='x', rotation=45)
        
        # Agregar valores en las barras
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 100,
                    f'{count:,}', ha='center', va='bottom')
        
        # Gr√°fico de pastel para top 5
        top5_langs = list(lang_usage.keys())[:5]
        top5_counts = list(lang_usage.values())[:5]
        others_count = sum(list(lang_usage.values())[5:])
        
        if others_count > 0:
            top5_langs.append('Otros')
            top5_counts.append(others_count)
        
        ax2.pie(top5_counts, labels=top5_langs, autopct='%1.1f%%', 
                colors=self.colors[:len(top5_langs)])
        ax2.set_title('Distribuci√≥n Top 5 + Otros', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('analisis_lenguajes_programacion.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas
        print("Top 10 lenguajes de programaci√≥n:")
        for i, (lang, count) in enumerate(list(lang_usage.items())[:10], 1):
            percentage = (count / len(self.df)) * 100
            print(f"  {i:2d}. {lang}: {count:,} usuarios ({percentage:.1f}%)")
    
    def analisis_herramientas_desarrollo(self):
        """
        An√°lisis de herramientas de desarrollo (IDEs, editores)
        """
        print("\nüîß AN√ÅLISIS DE HERRAMIENTAS DE DESARROLLO")
        print("=" * 50)
        
        # Identificar columnas de IDEs
        ide_columns = [col for col in self.df.columns if col.startswith('IDE_') and col != 'IDE_Otros_Texto_Libre']
        
        if not ide_columns:
            print("No se encontraron columnas de IDEs")
            return
        
        # Contar uso de cada IDE
        ide_usage = {}
        for col in ide_columns:
            ide_name = col.replace('IDE_', '').replace('_', ' ')
            count = self.df[col].notna().sum()
            ide_usage[ide_name] = count
        
        # Ordenar por uso
        ide_usage = dict(sorted(ide_usage.items(), key=lambda x: x[1], reverse=True))
        
        # Crear visualizaci√≥n
        fig, ax = plt.subplots(figsize=(15, 10))
        
        ides = list(ide_usage.keys())
        counts = list(ide_usage.values())
        
        bars = ax.barh(ides, counts, color=self.colors[:len(ides)])
        ax.set_title('Uso de IDEs y Editores de C√≥digo', fontsize=16, fontweight='bold')
        ax.set_xlabel('N√∫mero de Usuarios')
        
        # Agregar valores en las barras
        for bar, count in zip(bars, counts):
            width = bar.get_width()
            ax.text(width + 50, bar.get_y() + bar.get_height()/2.,
                   f'{count:,}', ha='left', va='center')
        
        plt.tight_layout()
        plt.savefig('analisis_herramientas_desarrollo.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas
        print("Uso de IDEs y editores:")
        for i, (ide, count) in enumerate(ide_usage.items(), 1):
            percentage = (count / len(self.df)) * 100
            print(f"  {i:2d}. {ide}: {count:,} usuarios ({percentage:.1f}%)")
    
    def analisis_cloud_platforms(self):
        """
        An√°lisis de plataformas de computaci√≥n en la nube
        """
        print("\n‚òÅÔ∏è AN√ÅLISIS DE PLATAFORMAS DE NUBE")
        print("=" * 50)
        
        # Identificar columnas de cloud
        cloud_columns = [col for col in self.df.columns if col.startswith('Cloud_') and col != 'Cloud_Otros_Texto_Libre']
        
        if not cloud_columns:
            print("No se encontraron columnas de plataformas de nube")
            return
        
        # Contar uso de cada plataforma
        cloud_usage = {}
        for col in cloud_columns:
            cloud_name = col.replace('Cloud_', '').replace('_', ' ')
            count = self.df[col].notna().sum()
            cloud_usage[cloud_name] = count
        
        # Ordenar por uso
        cloud_usage = dict(sorted(cloud_usage.items(), key=lambda x: x[1], reverse=True))
        
        # Crear visualizaci√≥n
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
        fig.suptitle('An√°lisis de Plataformas de Computaci√≥n en la Nube', fontsize=18, fontweight='bold')
        
        # Gr√°fico de barras
        platforms = list(cloud_usage.keys())
        counts = list(cloud_usage.values())
        
        bars = ax1.bar(platforms, counts, color=self.colors[:len(platforms)])
        ax1.set_title('Uso de Plataformas de Nube', fontweight='bold')
        ax1.set_ylabel('N√∫mero de Usuarios')
        ax1.tick_params(axis='x', rotation=45)
        
        # Agregar valores en las barras
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 50,
                    f'{count:,}', ha='center', va='bottom')
        
        # Gr√°fico de pastel
        ax2.pie(counts, labels=platforms, autopct='%1.1f%%', 
                colors=self.colors[:len(platforms)])
        ax2.set_title('Distribuci√≥n de Plataformas de Nube', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('analisis_cloud_platforms.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas
        print("Uso de plataformas de nube:")
        for i, (platform, count) in enumerate(cloud_usage.items(), 1):
            percentage = (count / len(self.df)) * 100
            print(f"  {i:2d}. {platform}: {count:,} usuarios ({percentage:.1f}%)")
    
    def analisis_salarios_experiencia(self):
        """
        An√°lisis de salarios vs experiencia
        """
        print("\nüí∞ AN√ÅLISIS DE SALARIOS Y EXPERIENCIA")
        print("=" * 50)
        
        # Verificar que las columnas necesarias existen
        if 'Categoria_Salarial' not in self.df.columns or 'Categoria_Experiencia' not in self.df.columns:
            print("No se encontraron las columnas de categor√≠as de salario y experiencia")
            return
        
        # Crear tabla de contingencia
        salary_exp_cross = pd.crosstab(self.df['Categoria_Experiencia'], 
                                     self.df['Categoria_Salarial'], 
                                     normalize='index') * 100
        
        # Crear heatmap
        fig, ax = plt.subplots(figsize=(12, 8))
        
        sns.heatmap(salary_exp_cross, annot=True, fmt='.1f', cmap='YlOrRd', 
                   cbar_kws={'label': 'Porcentaje (%)'}, ax=ax)
        
        ax.set_title('Relaci√≥n entre Experiencia y Salario\n(Porcentaje por nivel de experiencia)', 
                    fontsize=16, fontweight='bold')
        ax.set_xlabel('Categor√≠a Salarial')
        ax.set_ylabel('Categor√≠a de Experiencia')
        
        plt.tight_layout()
        plt.savefig('analisis_salarios_experiencia.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas adicionales
        print("Distribuci√≥n de salarios por experiencia:")
        for exp_level in self.df['Categoria_Experiencia'].unique():
            if exp_level != 'No especificado':
                exp_data = self.df[self.df['Categoria_Experiencia'] == exp_level]
                salary_dist = exp_data['Categoria_Salarial'].value_counts()
                print(f"\n{exp_level}:")
                for salary, count in salary_dist.items():
                    percentage = (count / len(exp_data)) * 100
                    print(f"  ‚Ä¢ {salary}: {count:,} ({percentage:.1f}%)")
    
    def analisis_areas_estudio(self):
        """
        An√°lisis de √°reas de estudio y su relaci√≥n con roles
        """
        print("\nüéì AN√ÅLISIS DE √ÅREAS DE ESTUDIO")
        print("=" * 50)
        
        if 'Area_Estudios_Principal' not in self.df.columns or 'Cargo_Principal_Trabajo' not in self.df.columns:
            print("No se encontraron las columnas de √°rea de estudios y cargo")
            return
        
        # Top √°reas de estudio
        area_counts = self.df['Area_Estudios_Principal'].value_counts().head(10)
        
        # Crear visualizaci√≥n
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
        fig.suptitle('An√°lisis de √Åreas de Estudio', fontsize=18, fontweight='bold')
        
        # Gr√°fico de barras
        areas = area_counts.index
        counts = area_counts.values
        
        bars = ax1.barh(areas, counts, color=self.colors[:len(areas)])
        ax1.set_title('Top 10 √Åreas de Estudio', fontweight='bold')
        ax1.set_xlabel('N√∫mero de Encuestados')
        
        # Agregar valores en las barras
        for bar, count in zip(bars, counts):
            width = bar.get_width()
            ax1.text(width + 50, bar.get_y() + bar.get_height()/2.,
                   f'{count:,}', ha='left', va='center')
        
        # Relaci√≥n √°rea de estudio vs cargo
        area_role_cross = pd.crosstab(self.df['Area_Estudios_Principal'], 
                                    self.df['Cargo_Principal_Trabajo'])
        
        # Seleccionar solo los cargos m√°s comunes
        top_roles = self.df['Cargo_Principal_Trabajo'].value_counts().head(5).index
        area_role_subset = area_role_cross[top_roles]
        
        # Crear heatmap
        sns.heatmap(area_role_subset, annot=True, fmt='d', cmap='Blues', 
                   cbar_kws={'label': 'N√∫mero de Personas'}, ax=ax2)
        
        ax2.set_title('√Årea de Estudio vs Cargo Principal', fontweight='bold')
        ax2.set_xlabel('Cargo Principal')
        ax2.set_ylabel('√Årea de Estudio')
        
        plt.tight_layout()
        plt.savefig('analisis_areas_estudio.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Estad√≠sticas
        print("Top 10 √°reas de estudio:")
        for i, (area, count) in enumerate(area_counts.items(), 1):
            percentage = (count / len(self.df)) * 100
            print(f"  {i:2d}. {area}: {count:,} ({percentage:.1f}%)")
    
    def generar_reporte_completo(self):
        """
        Genera un reporte completo con todas las visualizaciones
        """
        print("üöÄ GENERANDO REPORTE COMPLETO DE AN√ÅLISIS")
        print("=" * 60)
        
        # Ejecutar todos los an√°lisis
        self.analisis_demografico()
        self.analisis_lenguajes_programacion()
        self.analisis_herramientas_desarrollo()
        self.analisis_cloud_platforms()
        self.analisis_salarios_experiencia()
        self.analisis_areas_estudio()
        
        print("\n‚úÖ REPORTE COMPLETO GENERADO")
        print("üìÅ Archivos de visualizaci√≥n creados:")
        print("   ‚Ä¢ analisis_demografico.png")
        print("   ‚Ä¢ analisis_lenguajes_programacion.png")
        print("   ‚Ä¢ analisis_herramientas_desarrollo.png")
        print("   ‚Ä¢ analisis_cloud_platforms.png")
        print("   ‚Ä¢ analisis_salarios_experiencia.png")
        print("   ‚Ä¢ analisis_areas_estudio.png")
        
        # Crear resumen ejecutivo
        self.crear_resumen_ejecutivo()
    
    def crear_resumen_ejecutivo(self):
        """
        Crea un resumen ejecutivo del an√°lisis
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"resumen_ejecutivo_analisis_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RESUMEN EJECUTIVO - AN√ÅLISIS KAGGLE SURVEY 2019\n")
            f.write("Enfoque: Ingenier√≠a de Sistemas\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"Fecha de an√°lisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total de encuestados analizados: {len(self.df):,}\n\n")
            
            f.write("HALLAZGOS PRINCIPALES:\n")
            f.write("-" * 30 + "\n\n")
            
            # Demograf√≠a
            if 'Genero' in self.df.columns:
                gender_dist = self.df['Genero'].value_counts()
                f.write("1. DEMOGRAF√çA:\n")
                for gender, count in gender_dist.items():
                    percentage = (count / len(self.df)) * 100
                    f.write(f"   ‚Ä¢ {gender}: {percentage:.1f}%\n")
                f.write("\n")
            
            # Lenguajes de programaci√≥n
            lang_columns = [col for col in self.df.columns if col.startswith('Lenguaje_') and col != 'Lenguaje_Otros_Texto_Libre']
            if lang_columns:
                f.write("2. LENGUAJES DE PROGRAMACI√ìN M√ÅS USADOS:\n")
                lang_usage = {}
                for col in lang_columns:
                    lang_name = col.replace('Lenguaje_', '').replace('_', ' ')
                    count = self.df[col].notna().sum()
                    lang_usage[lang_name] = count
                
                lang_usage = dict(sorted(lang_usage.items(), key=lambda x: x[1], reverse=True))
                for i, (lang, count) in enumerate(list(lang_usage.items())[:5], 1):
                    percentage = (count / len(self.df)) * 100
                    f.write(f"   {i}. {lang}: {percentage:.1f}%\n")
                f.write("\n")
            
            # Plataformas de nube
            cloud_columns = [col for col in self.df.columns if col.startswith('Cloud_') and col != 'Cloud_Otros_Texto_Libre']
            if cloud_columns:
                f.write("3. PLATAFORMAS DE NUBE M√ÅS USADAS:\n")
                cloud_usage = {}
                for col in cloud_columns:
                    cloud_name = col.replace('Cloud_', '').replace('_', ' ')
                    count = self.df[col].notna().sum()
                    cloud_usage[cloud_name] = count
                
                cloud_usage = dict(sorted(cloud_usage.items(), key=lambda x: x[1], reverse=True))
                for i, (platform, count) in enumerate(list(cloud_usage.items())[:3], 1):
                    percentage = (count / len(self.df)) * 100
                    f.write(f"   {i}. {platform}: {percentage:.1f}%\n")
                f.write("\n")
            
            f.write("RECOMENDACIONES PARA INGENIER√çA DE SISTEMAS:\n")
            f.write("-" * 40 + "\n")
            f.write("1. Enfocar la formaci√≥n en los lenguajes de programaci√≥n m√°s demandados\n")
            f.write("2. Incluir capacitaci√≥n en las principales plataformas de nube\n")
            f.write("3. Desarrollar competencias en herramientas de desarrollo modernas\n")
            f.write("4. Considerar las tendencias salariales por nivel de experiencia\n")
            f.write("5. Adaptar el curr√≠culo seg√∫n las √°reas de estudio m√°s relevantes\n")
        
        print(f"üìÑ Resumen ejecutivo creado: {filename}")

def main():
    """
    Funci√≥n principal para ejecutar el an√°lisis
    """
    # Cargar el dataset limpio
    try:
        # Buscar el archivo CSV m√°s reciente
        import glob
        csv_files = glob.glob("kaggle_survey_cleaned_*.csv")
        if not csv_files:
            print("‚ùå No se encontr√≥ el archivo de dataset limpio")
            print("Ejecuta primero el script etl_kaggle_survey.py")
            return
        
        # Usar el archivo m√°s reciente
        latest_file = max(csv_files, key=os.path.getctime)
        print(f"üìÅ Cargando dataset limpio: {latest_file}")
        
        df_cleaned = pd.read_csv(latest_file)
        
        # Crear instancia del analizador
        analyzer = AnalisisVisualizaciones(df_cleaned)
        
        # Generar reporte completo
        analyzer.generar_reporte_completo()
        
    except Exception as e:
        print(f"‚ùå Error al ejecutar el an√°lisis: {str(e)}")

if __name__ == "__main__":
    import os
    main()
